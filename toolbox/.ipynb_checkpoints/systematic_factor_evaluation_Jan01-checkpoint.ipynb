{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Systematic Factor Evaluation<h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show/hide the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to show/hide the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import alphalens\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import getpass\n",
    "import logging\n",
    "import sklearn\n",
    "from sklearn.base import clone\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm_api\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dask import delayed\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "%autosave 0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from dslab.dsdata import MLData\n",
    "from dslab.dsmodel import MLModel\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output, Image, Javascript, SVG\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.tools import FigureFactory as FF       \n",
    "\n",
    "# Initialize data and model object instances\n",
    "dsData = MLData(regret=True)\n",
    "model_obj = MLModel()\n",
    "\n",
    "# for plotly\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import scipy.interpolate\n",
    "import itertools\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.stats import norm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display settings\n",
    "\n",
    "# widgets\n",
    "row_layout = Layout(display='flex', flex_flow='row', align_items='center')\n",
    "col_layout = dict(display='flex', flex_flow='column', justify_content='space-between', width='auto')\n",
    "\n",
    "def leftm(m=10):\n",
    "    '''Set left margin'''\n",
    "    return '0px 0px 0px {}px'.format(m)\n",
    "\n",
    "max_col = IntSlider(value=50, max=100, width='600px')\n",
    "max_row = IntSlider(value=100, max=250, width='600px')\n",
    "\n",
    "bs_row1 = Box([Label('Max Columns to Display:', layout=Layout(width='200px')),  max_col], layout=row_layout)\n",
    "bs_row2 = Box([Label('Max Rows to Display:', layout=Layout(width='200px')),  max_row], layout=row_layout)\n",
    "# display(Box([bs_row1, bs_row2], layout=Layout(**col_layout)))\n",
    "\n",
    "# function\n",
    "pd.options.display.max_columns = max_col.value\n",
    "pd.options.display.max_rows = max_row.value\n",
    "\n",
    "def chg_setting(chg):\n",
    "    '''Change basic settings.'''\n",
    "    pd.options.display.max_rows = max_row.value\n",
    "    pd.options.display.max_columns = max_col.value\n",
    "\n",
    "max_col.observe(chg_setting, names='value')\n",
    "max_row.observe(chg_setting, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Head\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sid</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Constant_nonConstant</th>\n",
       "      <th>EPS_surprise</th>\n",
       "      <th>Sector</th>\n",
       "      <th>price_to_book</th>\n",
       "      <th>transactions</th>\n",
       "      <th>returns_1mo_forward</th>\n",
       "      <th>returns_3mo_forward</th>\n",
       "      <th>transactions$YoY</th>\n",
       "      <th>transactions$QoQ</th>\n",
       "      <th>transactions$QQYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>1234</td>\n",
       "      <td>CAKE</td>\n",
       "      <td>0.933179</td>\n",
       "      <td>-0.007353</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>3.99316</td>\n",
       "      <td>3.747790e+08</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>-0.002958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>1787</td>\n",
       "      <td>COST</td>\n",
       "      <td>1.218542</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>2.61398</td>\n",
       "      <td>6.597873e+09</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>0.091378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>3496</td>\n",
       "      <td>HD</td>\n",
       "      <td>1.365184</td>\n",
       "      <td>0.054695</td>\n",
       "      <td>Consumer Cyclicals</td>\n",
       "      <td>3.33687</td>\n",
       "      <td>2.787000e+10</td>\n",
       "      <td>-0.024491</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>3846</td>\n",
       "      <td>DIN</td>\n",
       "      <td>2.117332</td>\n",
       "      <td>0.135531</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>2.49685</td>\n",
       "      <td>3.272870e+08</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>-0.008905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>4313</td>\n",
       "      <td>KSS</td>\n",
       "      <td>2.502261</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>2.82385</td>\n",
       "      <td>3.995940e+09</td>\n",
       "      <td>-0.060363</td>\n",
       "      <td>0.092550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   sid symbol  Constant_nonConstant  EPS_surprise  \\\n",
       "0  2006-01-03  1234   CAKE              0.933179     -0.007353   \n",
       "1  2006-01-03  1787   COST              1.218542      0.006901   \n",
       "2  2006-01-03  3496     HD              1.365184      0.054695   \n",
       "3  2006-01-03  3846    DIN              2.117332      0.135531   \n",
       "4  2006-01-03  4313    KSS              2.502261      0.006178   \n",
       "\n",
       "                   Sector  price_to_book  transactions  returns_1mo_forward  \\\n",
       "0       Consumer Services        3.99316  3.747790e+08             0.018553   \n",
       "1  Consumer Non-Cyclicals        2.61398  6.597873e+09            -0.007820   \n",
       "2      Consumer Cyclicals        3.33687  2.787000e+10            -0.024491   \n",
       "3       Consumer Services        2.49685  3.272870e+08             0.029802   \n",
       "4  Consumer Non-Cyclicals        2.82385  3.995940e+09            -0.060363   \n",
       "\n",
       "   returns_3mo_forward  transactions$YoY  transactions$QoQ  transactions$QQYY  \n",
       "0            -0.002958               NaN               NaN                NaN  \n",
       "1             0.091378               NaN               NaN                NaN  \n",
       "2             0.030616               NaN               NaN                NaN  \n",
       "3            -0.008905               NaN               NaN                NaN  \n",
       "4             0.092550               NaN               NaN                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Tail\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sid</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Constant_nonConstant</th>\n",
       "      <th>EPS_surprise</th>\n",
       "      <th>Sector</th>\n",
       "      <th>price_to_book</th>\n",
       "      <th>transactions</th>\n",
       "      <th>returns_1mo_forward</th>\n",
       "      <th>returns_3mo_forward</th>\n",
       "      <th>transactions$YoY</th>\n",
       "      <th>transactions$QoQ</th>\n",
       "      <th>transactions$QQYY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24342</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>3846</td>\n",
       "      <td>DIN</td>\n",
       "      <td>1.337881</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>3.15025</td>\n",
       "      <td>-1.656700e+07</td>\n",
       "      <td>0.139908</td>\n",
       "      <td>0.381292</td>\n",
       "      <td>-0.808770</td>\n",
       "      <td>-0.587413</td>\n",
       "      <td>-0.520992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24343</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>4313</td>\n",
       "      <td>KSS</td>\n",
       "      <td>2.010939</td>\n",
       "      <td>0.026666</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>2.32688</td>\n",
       "      <td>1.322400e+10</td>\n",
       "      <td>0.041604</td>\n",
       "      <td>0.068697</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>1.336750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>12652</td>\n",
       "      <td>DLTR</td>\n",
       "      <td>1.600609</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>2.55136</td>\n",
       "      <td>4.666900e+09</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.147808</td>\n",
       "      <td>0.580607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>12882</td>\n",
       "      <td>DRI</td>\n",
       "      <td>0.399856</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>6.23661</td>\n",
       "      <td>6.935000e+08</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.214712</td>\n",
       "      <td>0.346602</td>\n",
       "      <td>0.054592</td>\n",
       "      <td>-1.677987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>43201</td>\n",
       "      <td>FIVE</td>\n",
       "      <td>2.914763</td>\n",
       "      <td>0.092467</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>12.84670</td>\n",
       "      <td>1.725730e+08</td>\n",
       "      <td>0.187921</td>\n",
       "      <td>0.179908</td>\n",
       "      <td>2.893180</td>\n",
       "      <td>0.084976</td>\n",
       "      <td>-0.703690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    sid symbol  Constant_nonConstant  EPS_surprise  \\\n",
       "24342  2018-12-31   3846    DIN              1.337881      0.004926   \n",
       "24343  2018-12-31   4313    KSS              2.010939      0.026666   \n",
       "24344  2018-12-31  12652   DLTR              1.600609      0.031481   \n",
       "24345  2018-12-31  12882    DRI              0.399856      0.010816   \n",
       "24346  2018-12-31  43201   FIVE              2.914763      0.092467   \n",
       "\n",
       "                       Sector  price_to_book  transactions  \\\n",
       "24342       Consumer Services        3.15025 -1.656700e+07   \n",
       "24343  Consumer Non-Cyclicals        2.32688  1.322400e+10   \n",
       "24344  Consumer Non-Cyclicals        2.55136  4.666900e+09   \n",
       "24345       Consumer Services        6.23661  6.935000e+08   \n",
       "24346  Consumer Non-Cyclicals       12.84670  1.725730e+08   \n",
       "\n",
       "       returns_1mo_forward  returns_3mo_forward  transactions$YoY  \\\n",
       "24342             0.139908             0.381292         -0.808770   \n",
       "24343             0.041604             0.068697          0.046948   \n",
       "24344             0.063441             0.147808          0.580607   \n",
       "24345             0.070588             0.214712          0.346602   \n",
       "24346             0.187921             0.179908          2.893180   \n",
       "\n",
       "       transactions$QoQ  transactions$QQYY  \n",
       "24342         -0.587413          -0.520992  \n",
       "24343          0.004634           1.336750  \n",
       "24344          0.000000                NaN  \n",
       "24345          0.054592          -1.677987  \n",
       "24346          0.084976          -0.703690  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary Statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>unique</th>\n",
       "      <th>count</th>\n",
       "      <th>nulls</th>\n",
       "      <th>mode</th>\n",
       "      <th>mode_freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50% (median)</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>object</td>\n",
       "      <td>3271</td>\n",
       "      <td>24347</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sid</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7975.04251</td>\n",
       "      <td>9905.318632</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>3846.0</td>\n",
       "      <td>12652.0</td>\n",
       "      <td>43201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>symbol</td>\n",
       "      <td>category</td>\n",
       "      <td>8</td>\n",
       "      <td>24347</td>\n",
       "      <td>0</td>\n",
       "      <td>CAKE</td>\n",
       "      <td>3271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Constant_nonConstant</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.411393</td>\n",
       "      <td>0.651244</td>\n",
       "      <td>0.367995</td>\n",
       "      <td>1.018217</td>\n",
       "      <td>1.248903</td>\n",
       "      <td>1.878353</td>\n",
       "      <td>3.294957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPS_surprise</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>0.61063</td>\n",
       "      <td>-7.818213</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.027408</td>\n",
       "      <td>0.074199</td>\n",
       "      <td>4.10969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sector</td>\n",
       "      <td>category</td>\n",
       "      <td>3</td>\n",
       "      <td>24347</td>\n",
       "      <td>0</td>\n",
       "      <td>Consumer Non-Cyclicals</td>\n",
       "      <td>11263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>price_to_book</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.57894</td>\n",
       "      <td>13.52654</td>\n",
       "      <td>1.25285</td>\n",
       "      <td>2.84917</td>\n",
       "      <td>3.59609</td>\n",
       "      <td>5.57972</td>\n",
       "      <td>165.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transactions</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6099890965.827412</td>\n",
       "      <td>8861744481.495373</td>\n",
       "      <td>-200433000.0</td>\n",
       "      <td>589631000.0</td>\n",
       "      <td>1774000000.0</td>\n",
       "      <td>7585000000.0</td>\n",
       "      <td>45235000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>returns_1mo_forward</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24345.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01319</td>\n",
       "      <td>0.099196</td>\n",
       "      <td>-0.659868</td>\n",
       "      <td>-0.034812</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.05762</td>\n",
       "      <td>1.669742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>returns_3mo_forward</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24345.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041769</td>\n",
       "      <td>0.194894</td>\n",
       "      <td>-0.737782</td>\n",
       "      <td>-0.047103</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>0.123562</td>\n",
       "      <td>4.527122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>transactions$YoY</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22329.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.716021</td>\n",
       "      <td>-3.755742</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.084848</td>\n",
       "      <td>0.14435</td>\n",
       "      <td>11.072193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transactions$QoQ</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23842.0</td>\n",
       "      <td>505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110194</td>\n",
       "      <td>2.14245</td>\n",
       "      <td>-1.435278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.038044</td>\n",
       "      <td>47.148452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>transactions$QQYY</td>\n",
       "      <td>float</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18584.0</td>\n",
       "      <td>5763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-0.641481</td>\n",
       "      <td>-0.141573</td>\n",
       "      <td>0.226064</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column name     dtype unique    count  nulls  \\\n",
       "0                   date    object   3271    24347      0   \n",
       "1                    sid       int    NaN  24347.0      0   \n",
       "2                 symbol  category      8    24347      0   \n",
       "3   Constant_nonConstant     float    NaN  24347.0      0   \n",
       "4           EPS_surprise     float    NaN  24347.0      0   \n",
       "5                 Sector  category      3    24347      0   \n",
       "6          price_to_book     float    NaN  24347.0      0   \n",
       "7           transactions     float    NaN  24347.0      0   \n",
       "8    returns_1mo_forward     float    NaN  24345.0      2   \n",
       "9    returns_3mo_forward     float    NaN  24345.0      2   \n",
       "10      transactions$YoY     float    NaN  22329.0   2018   \n",
       "11      transactions$QoQ     float    NaN  23842.0    505   \n",
       "12     transactions$QQYY     float    NaN  18584.0   5763   \n",
       "\n",
       "                      mode mode_freq               mean                std  \\\n",
       "0               2016-03-24         8                NaN                NaN   \n",
       "1                      NaN       NaN         7975.04251        9905.318632   \n",
       "2                     CAKE      3271                NaN                NaN   \n",
       "3                      NaN       NaN           1.411393           0.651244   \n",
       "4                      NaN       NaN           0.016219            0.61063   \n",
       "5   Consumer Non-Cyclicals     11263                NaN                NaN   \n",
       "6                      NaN       NaN            6.57894           13.52654   \n",
       "7                      NaN       NaN  6099890965.827412  8861744481.495373   \n",
       "8                      NaN       NaN            0.01319           0.099196   \n",
       "9                      NaN       NaN           0.041769           0.194894   \n",
       "10                     NaN       NaN           0.071189           0.716021   \n",
       "11                     NaN       NaN           0.110194            2.14245   \n",
       "12                     NaN       NaN                NaN                NaN   \n",
       "\n",
       "            min          25%  50% (median)           75%            max  \n",
       "0           NaN          NaN           NaN           NaN            NaN  \n",
       "1        1234.0       1787.0        3846.0       12652.0        43201.0  \n",
       "2           NaN          NaN           NaN           NaN            NaN  \n",
       "3      0.367995     1.018217      1.248903      1.878353       3.294957  \n",
       "4     -7.818213     0.001073      0.027408      0.074199        4.10969  \n",
       "5           NaN          NaN           NaN           NaN            NaN  \n",
       "6       1.25285      2.84917       3.59609       5.57972        165.043  \n",
       "7  -200433000.0  589631000.0  1774000000.0  7585000000.0  45235000000.0  \n",
       "8     -0.659868    -0.034812      0.012357       0.05762       1.669742  \n",
       "9     -0.737782    -0.047103      0.035326      0.123562       4.527122  \n",
       "10    -3.755742      0.00594      0.084848       0.14435      11.072193  \n",
       "11    -1.435278          0.0      0.019452      0.038044      47.148452  \n",
       "12         -inf    -0.641481     -0.141573      0.226064            inf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "# widgets\n",
    "filepath = Text(description='File Path:', value='fake_data.csv')\n",
    "loaddata_button = Button(description=\"Load Data\", button_style='success', margin=leftm(650))\n",
    "prog = FloatProgress(value=0, min=0, max=10, step=1, description='Progress:',\n",
    "                     margin=leftm(550), width='250px')\n",
    "display(filepath, loaddata_button, prog)\n",
    "\n",
    "# functions\n",
    "def loaddata(b):\n",
    "    '''Load data.'''\n",
    "#     clear_output()\n",
    "#     display(filepath, loaddata_button, prog)\n",
    "    global all_tickers, all_factors\n",
    "    prog.value = 0\n",
    "    prog.description = 'Start...'\n",
    "    filepath_ = filepath.value # os.path.join(PATH.value, filename.value)\n",
    "    dsData.read_data(filepath_)  # read data\n",
    "    prog.value = 5\n",
    "    prog.description = 'In Progress...'\n",
    "    dsData.save_current()  # save a copy of current snapshot\n",
    "    prog.value = 10\n",
    "    prog.description = 'Done!'\n",
    "    dsData.infer_categorical()\n",
    "    clear_output()\n",
    "    print('\\n', 'Data Head')\n",
    "    display(dsData.head())  # display data head\n",
    "    print('\\n', 'Data Tail')\n",
    "    display(dsData.tail())  # display data tail\n",
    "    print('\\n', 'Summary Statistics')    \n",
    "    display(dsData.get_summary())  # display summary statistics\n",
    "    \n",
    "    all_tickers = list(dsData.data['symbol'].unique())\n",
    "    all_factors = [j for j in dsData.data.columns if j not in ['date', 'sid', 'symbol', 'Sector']]\n",
    "\n",
    "loaddata_button.on_click(loaddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad67854bdc254aea972fa6893873b8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Graph Type: '), ToggleButtons(index=4, options=('Coverage', 'Pie Chart', 'Histograâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select Graph\n",
    "\n",
    "# widgets\n",
    "chart_select = ToggleButtons(\n",
    "    options=['Coverage', 'Pie Chart', 'Histogram', 'Scatter Plot', 'Correlations'],\n",
    "    tooltips=['Explore feature coverage', 'Visualize single categorical variable', 'Visualize single numerical variable',\n",
    "             'Visualize pairwise distributions among a group of numerical variables',\n",
    "             'Visualize pairwise correlations among a group of numerical variables'],\n",
    "    value='Correlations', \n",
    "    margin=leftm()\n",
    ")\n",
    "\n",
    "display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "# functions\n",
    "grph = HTML('')\n",
    "\n",
    "def switch_chart(chg):\n",
    "    '''Switch between graph type.'''\n",
    "    global grph\n",
    "    clear_output()\n",
    "    display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "    grph.close()\n",
    "    grph = graph_mapping[chart_select.value]()\n",
    "    display(grph)\n",
    "\n",
    "chart_select.observe(switch_chart, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage check\n",
    "# widgets\n",
    "def make_coverage():    \n",
    "    coverage_b = Button(description=\"Coverage\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    \n",
    "    row0 = Box([HTML('<h4>Pie Chart - Visualize Distributions of Categorical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([Label(layout=Layout(width='200px')), coverage_b], layout=row_layout)\n",
    "    coverage_chart = Box([row0, row1], layout=Layout(**col_layout),\n",
    "                    height='160px')    \n",
    "    return(coverage_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "# widgets\n",
    "def make_pie():\n",
    "    '''create widgets for pie chart'''\n",
    "    global pie_filter, pie_select, pie_limit, group_less_freq, pieb\n",
    "    pie_filter = Text(value='', width='500px')\n",
    "    pie_select = Dropdown(options=dsData.get_header(sort=True), height='30px', width='200px',\n",
    "                          margin=leftm())\n",
    "    pie_limit = IntText(value=20, width='70px')\n",
    "    group_less_freq = Checkbox(value=False)\n",
    "    pieb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    \n",
    "    row0 = Box([HTML('<h4>Pie Chart - Visualize Distributions of Categorical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "#     row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), pie_filter, pieb], layout=row_layout)\n",
    "    row1 = Box([Label('Pie Chart Plot: ', layout=Layout(width='200px')), pieb], layout=row_layout)\n",
    "#     row1 = Box([pieb], layout=row_layout)\n",
    "    row2 = Box([Label('Select a Categorical Column: ', layout=Layout(width='200px')), pie_select,\n",
    "                Label('Limit on # of Values: ', layout=Layout(width='200px'), margin=leftm(20)), pie_limit], layout=row_layout)\n",
    "    row3 = Box([Label('Group Everything Below the Limit as \"others\": ', layout=Layout(width='400px')), group_less_freq],\n",
    "                layout=row_layout)\n",
    "    pie_chart = Box([row0, row1, row2, row3], layout=Layout(**col_layout),\n",
    "                    height='160px')\n",
    "\n",
    "    pie_select.observe(plot_pie, names='value')\n",
    "    pieb.on_click(plot_pie)\n",
    "    return pie_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_pie(chg):\n",
    "    '''plot the pie chart'''\n",
    "#     with warnings.catch_warnings():\n",
    "#         print(\"ignore warning\")\n",
    "#         warnings.simplefilter('ignore')\n",
    "    clear_output()\n",
    "    display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px'))) ## kai test\n",
    "\n",
    "    if pie_filter.value.strip() != '':\n",
    "        try:\n",
    "            vc = dsData.query_chain(pie_filter.value).ct_freq(pie_select.value, group_less_freq.value,\n",
    "                                                           pie_limit.value)\n",
    "            vc.astype('category').cat.remove_unused_categories(True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            vc = dsData.ct_freq(pie_select.value, group_less_freq.value, pie_limit.value)\n",
    "    else:\n",
    "        vc = dsData.ct_freq(pie_select.value, group_less_freq.value, pie_limit.value)\n",
    "    trace = go.Pie(labels=list(vc.index), values=vc.values)\n",
    "    figp = go.Figure(data=go.Data([trace]),\n",
    "                     layout=dict(title='Break Down of {}'.format(pie_select.value.upper())))\n",
    "    iplot(figp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "# widgets\n",
    "def make_hist():\n",
    "    '''make widgets for histogram'''\n",
    "    global hist_filter, histb, hist_select, hist_min, hist_max, hist_bins\n",
    "    hist_filter = Text(value='', width='500px')\n",
    "    histb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                   margin=leftm(20))\n",
    "    hist_select = Dropdown(options=dsData.get_header(['int', 'float'], sort=True), height='30px',\n",
    "                           width='200px', margin=leftm())\n",
    "    hist_min = FloatText(value=float('-Inf'), width='70px')\n",
    "    hist_max = FloatText(value=float('Inf'), width='70px')\n",
    "    hist_bins = IntText(value=10, width='70px')\n",
    "    \n",
    "    row0 = Box([HTML('<h4>Histogram - Visualize Distributions of Numerical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "#     row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), hist_filter, histb], layout=row_layout)\n",
    "    row1 = Box([Label('Histogram Plot: ', layout=Layout(width='200px')), histb], layout=row_layout)\n",
    "        \n",
    "    row2 = Box([Label('Select a Numerical Column: ', layout=Layout(width='200px')), hist_select], layout=row_layout)\n",
    "    row3 = Box([Label('Min: ', layout=Layout(width='200px')), hist_min, Label('Max: ', margin=leftm(20)), hist_max,\n",
    "                Label('# of Bins: ', margin=leftm(20)), hist_bins], layout=row_layout)\n",
    "\n",
    "    hist_chart = Box([row0, row1, row2, row3], layout=Layout(**col_layout), height='160px')\n",
    "    \n",
    "    hist_select.observe(plot_hist_new_col)\n",
    "    histb.on_click(plot_hist)\n",
    "    return hist_chart\n",
    "\n",
    "\n",
    "# functions\n",
    "def plot_hist_new_col(chg):\n",
    "    '''plot histogram when switching columns'''\n",
    "    hist_min.value = float('-Inf')\n",
    "    hist_max.value = float('Inf')\n",
    "    plot_hist(chg)\n",
    "    \n",
    "def plot_hist(chg):\n",
    "    '''plot histogram'''\n",
    "    clear_output()\n",
    "    display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px'))) ## kai test\n",
    "    if hist_filter.value.strip() != '':\n",
    "        x = dsData.query(hist_filter.value)[hist_select.value]\n",
    "    else:\n",
    "        x = dsData.data[hist_select.value]\n",
    "    n = len(x)\n",
    "    x = x[x > hist_min.value]\n",
    "    x = x[x < hist_max.value]\n",
    "    print('Percentage covered (after filtering): {:.2f}%'.format(len(x) / n * 100))\n",
    "    if hist_min.value == float('-Inf'):\n",
    "        hist_min.value = np.round(np.min(x), 2) - 1\n",
    "    if hist_max.value == float('Inf'):\n",
    "        hist_max.value = np.round(np.max(x), 2) + 1\n",
    "\n",
    "    size = (hist_max.value - hist_min.value) / hist_bins.value\n",
    "    trh = go.Histogram(x=x, histnorm='percent', marker=dict(color='rgb(0,0,100)'),\n",
    "                       xbins=dict(start=hist_min.value - 0.5, size=size, end=hist_max.value + 0.5))\n",
    "\n",
    "    layout = dict(bargap= 0.015, hovermode= 'x',\n",
    "                  title='Histogram for {}'.format(hist_select.value.upper()),\n",
    "                  yaxis= dict(title='Percentage (%)', autorange= True, showticklabels= True))\n",
    "    figh = go.Figure(data=go.Data([trh]), layout=layout)\n",
    "    iplot(figh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "# widgets\n",
    "def make_scatter():\n",
    "    '''Make widgets for scatter plot.'''\n",
    "    global sp_filter, spb, sp_height, sp_select, sp_ccol\n",
    "    num_cols = dsData.get_header(['int', 'float'], sort=True)\n",
    "    sp_filter = Text(value='', width='500px')\n",
    "    spb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                 margin=leftm(20))\n",
    "    sp_height = np.min([300, np.max([len(num_cols) * 15, 100])])\n",
    "    sp_select = SelectMultiple(options=num_cols, margin=leftm(),\n",
    "                               height='{}px'.format(sp_height))\n",
    "    sp_ccol = Dropdown(options=[None] + dsData.get_header('category', sort=True), height='30px', width='200px', margin=leftm())\n",
    "\n",
    "    row0 = Box([HTML('<h4>Scatter Plot - Visualize Pairwise Distributions among a Group of Numerical '\n",
    "                     'Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "#     row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), sp_filter, spb], layout=row_layout)\n",
    "    row1 = Box([Label('Scatter Plot: ', layout=Layout(width='200px')), spb], layout=row_layout)\n",
    "    row2 = Box([Label(\"Select Columns: \", layout=Layout(width='200px')), sp_select, Label(\"Group by: \", margin=leftm(30)), sp_ccol],\n",
    "                layout=row_layout)\n",
    "    scatter_chart = Box([row0, row1, row2], layout=Layout(**col_layout),\n",
    "                        height='{}px'.format(sp_height + 110))\n",
    "    spb.on_click(plot_scatter)\n",
    "    return scatter_chart\n",
    "\n",
    "# functions\n",
    "def plot_scatter(chg):\n",
    "    '''Generate scatter plot.'''\n",
    "    clear_output()\n",
    "    display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px'))) ## kai test\n",
    "\n",
    "    if sp_filter.value.strip() != '':\n",
    "        temp_data = dsData.query(sp_filter.value).copy(True)\n",
    "    else:\n",
    "        temp_data = dsData.data.copy(True)\n",
    "    \n",
    "    sel_cols = list(sp_select.value)\n",
    "    if sp_ccol.value is not None:\n",
    "        temp_data[sp_ccol.value].cat.remove_unused_categories(True)\n",
    "        temp_data[sp_ccol.value] = temp_data[sp_ccol.value].astype('object')\n",
    "        sel_cols.append(sp_ccol.value)\n",
    "\n",
    "    temp = temp_data[sel_cols]\n",
    "    \n",
    "    fig = FF.create_scatterplotmatrix(temp, index=sp_ccol.value, diag='histogram', height=800,\n",
    "                                      width=800)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations\n",
    "# widgets\n",
    "def make_cor():\n",
    "    '''Make widgets for correlations plot.'''\n",
    "    global cor_filter, corb, cor_height, cor_select\n",
    "    num_cols = dsData.get_header(['int', 'float'], sort=True)\n",
    "    cor_filter = Text(value='', width='500px')\n",
    "    corb = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    cor_height = np.min([300, np.max([len(num_cols) * 15, 100])])\n",
    "    cor_select = SelectMultiple(options=num_cols, margin=leftm(),\n",
    "                                height='{}px'.format(cor_height))\n",
    "    row0 = Box([HTML('<h4>Correlations - Visualize Correlations among a Group of Numerical Variables</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "#     row1 = Box([Label('Filter by Criterion: ', layout=Layout(width='200px')), cor_filter, corb], layout=row_layout)\n",
    "    row1 = Box([Label('Correlation Plot: ', layout=Layout(width='200px')), corb], layout=row_layout)\n",
    "    row2 = Box([Label(\"Select Columns: \", layout=Layout(width='200px')), cor_select], layout=row_layout)\n",
    "    cor_chart = Box([row0, row1, row2], layout=Layout(**col_layout),\n",
    "                    height='{}px'.format(cor_height + 100))\n",
    "    corb.on_click(plot_cor)\n",
    "    return cor_chart\n",
    "\n",
    "# functions\n",
    "def plot_cor(chg):\n",
    "    '''Generate correlations plot.'''\n",
    "    clear_output()\n",
    "    display(HBox([Label('Graph Type: '), chart_select], layout=Layout(margin='0px 0px 30px 0px'))) ## kai test\n",
    "    \n",
    "    if cor_filter.value.strip() != '':\n",
    "        temp_data = dsData.query(cor_filter.value).copy(True)\n",
    "    else:\n",
    "        temp_data = dsData.data.copy(True)\n",
    "    \n",
    "    sel_cols = list(cor_select.value)\n",
    "    x, y = sel_cols, list(reversed(sel_cols))\n",
    "\n",
    "    corr = temp_data[sel_cols].corr().round(2)\n",
    "    z = np.flipud(corr.values)\n",
    "    annotations = []\n",
    "    for n, row in enumerate(z):\n",
    "        for m, val in enumerate(row):\n",
    "            var = z[n][m]\n",
    "            annotations.append(\n",
    "                dict(\n",
    "                    text=str(val),\n",
    "                    x=x[m], y=y[n],\n",
    "                    xref='x1', yref='y1',\n",
    "                    font=dict(color='black'),\n",
    "                    showarrow=False)\n",
    "                )\n",
    "\n",
    "    colorscale = [[0, 'rgba(255,0,0,0.3)'], [0.5, 'rgba(255,255,0,0.3)'], [1, 'rgba(0,255,0,0.3)']]\n",
    "    trace = go.Heatmap(x=x, y=y, z=z, zmin=-1, zmax=1, colorscale=colorscale, showscale=True)\n",
    "\n",
    "    fig = go.Figure(data=[trace])\n",
    "    fig['layout'].update(\n",
    "        title=\"Correlations\",\n",
    "        annotations=annotations,\n",
    "        xaxis=dict(ticks=''),\n",
    "        yaxis=dict(ticks='', ticksuffix='  '),\n",
    "        width=700,\n",
    "        height=700,\n",
    "        autosize=False\n",
    "    )\n",
    "    \n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_mapping = {'Pie Chart': make_pie, 'Histogram': make_hist, 'Box Plot': make_boxp,\n",
    "#                  'Cross Tab': make_xtab, 'Scatter Plot': make_scatter, 'Correlations': make_cor}\n",
    "\n",
    "graph_mapping = {'Coverage': make_coverage, 'Pie Chart': make_pie, 'Histogram': make_hist, \n",
    "                 'Scatter Plot': make_scatter, 'Correlations': make_cor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(b):\n",
    "    '''impute & update global variable mld.mldata'''\n",
    "    df = dsData.data.copy(deep=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    data_types = df.dtypes\n",
    "    \n",
    "    num_factor_cols = [j for j in df.columns if((data_types[j].name!='category') and (data_types[j].name!='object') \n",
    "                                                and (j != \"sid\") and (j != \"date\"))]\n",
    "                                                \n",
    "    cate_factor_cols = [j for j in df.columns if(((data_types[j].name=='category') or (data_types[j].name=='object')) \n",
    "                                                 and (j != \"sid\") and (j != \"date\"))]\n",
    "\n",
    "    ### first fillna for numerical columns\n",
    "    num_cols = ['date'] + num_factor_cols\n",
    "    df[num_factor_cols] = df[num_cols].groupby(\"date\").transform(lambda x: x.fillna(x.mean()))\n",
    "    ### first fillna for categorical columns\n",
    "    cate_cols = ['date'] + cate_factor_cols\n",
    "    df[cate_factor_cols] = df[cate_cols].groupby(\"date\").transform(lambda x: x.fillna(x.mode()))\n",
    "    df = df.dropna()  ### if still na, drop that row\n",
    "    dsData.data = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(b):\n",
    "#     univ_tickers = list(dsData.data['symbol'].unique())\n",
    "#     for this_ticker in univ_tickers:\n",
    "#         this_ticker = 'CAKE'\n",
    "#         this_feature = 'price_to_book'\n",
    "\n",
    "#         data = dsData.data.copy()\n",
    "#         data = data[data['symbol']==this_ticker]\n",
    "\n",
    "#         ticker_MLdata = MLData()\n",
    "#         ticker_MLdata.data = data\n",
    "\n",
    "#         ticker_YoY = ticker_MLdata.calculate_YoY(this_feature)\n",
    "#         ticker_QoQ = ticker_MLdata.calculate_QoQ(this_feature)\n",
    "#         ticker_QQYY = ticker_MLdata.calculate_QQYY(this_feature)        \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa56e642b5349cb959b4ca2083204f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Feature Extract (Default)', layout=Layout(height='40px', width='auâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53851c53d5d4675887c396ef0d909fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Data Imputation (Default)', layout=Layout(height='40px', width='auâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layout_data_impute = widgets.Layout(width='auto', height='40px') #set width and height\n",
    "feature_extraction = Button(description=\"Feature Extract (Default)\", button_style='success', \n",
    "                         width='500px', margin=leftm(5), layout=layout_data_impute)\n",
    "data_imputation = Button(description=\"Data Imputation (Default)\", button_style='success', \n",
    "                         width='500px', margin=leftm(5), layout=layout_data_impute)\n",
    "display(feature_extraction, data_imputation, height='120px', margin='10px 10px 10px 10px')\n",
    "feature_extraction.on_click(feature_extract)\n",
    "data_imputation.on_click(impute_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single Factor Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_hit(ts):\n",
    "    ts = ts.dropna()\n",
    "    same_sign_counts, diff_sign_counts = sum(ts > 0), sum(ts <= 0)\n",
    "    hit_rate = same_sign_counts / (same_sign_counts + diff_sign_counts)   \n",
    "    return(hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_factor_single_ticker(data):\n",
    "    current_ticker = data['symbol'].unique()[0]\n",
    "    print(\"single ticker: \", current_ticker)\n",
    "    display(data.tail(5))\n",
    "    compare_df = data[[factor_select.value, target_select.value]]\n",
    "    print(\"Correlation:\")\n",
    "    display(compare_df.corr())\n",
    "    print(\"Hit Rate (Same Sign):\")\n",
    "    check_sign = compare_df[factor_select.value] * compare_df[target_select.value]\n",
    "    check_sign.index = data[\"date\"]\n",
    "    check_sign = check_sign.dropna()\n",
    "    dates_remain = check_sign.index\n",
    "    check_sign = pd.Series(np.sign(check_sign))\n",
    "    check_sign.index = dates_remain\n",
    "    display(check_sign.tail(5))\n",
    "#     check_sign_mvg60 = check_sign.rolling(60).mean()\n",
    "    check_sign_mvg60 = check_sign.rolling(60).apply(cal_hit)\n",
    "    check_sign_mvg60.plot(rot=45)\n",
    "    same_sign_counts, diff_sign_counts = sum(check_sign > 0), sum(check_sign <= 0)\n",
    "    try:\n",
    "        hit_rate = same_sign_counts / (same_sign_counts + diff_sign_counts)\n",
    "    except:\n",
    "        print(\"denominator zeros: \", same_sign_counts, diff_sign_counts)\n",
    "        hit_rate = np.nan\n",
    "    print(\"Over the history Hit Rate: \", hit_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_factor(b):\n",
    "    target_cols = [target_select.value]\n",
    "#     cols = ['date', 'sid',  factor_select.value] + target_cols\n",
    "    cols = ['date', 'sid', 'symbol', factor_select.value] + target_cols\n",
    "\n",
    "    al_data = dsData.data[cols].copy()\n",
    "    ticker_selected = ticker_select.value\n",
    "    if ticker_selected != 'cross_tickers':\n",
    "        al_data = al_data[al_data['symbol']==ticker_selected]\n",
    "        run_single_factor_single_ticker(al_data)\n",
    "        return()\n",
    "        \n",
    "    al_data = al_data.drop(\"symbol\", axis=1)\n",
    "    al_data = al_data.set_index(['date', 'sid'])\n",
    "\n",
    "    factor_to_evaluate = al_data[factor_select.value]\n",
    "    forward_returns = al_data[target_select.value]   \n",
    "\n",
    "    data_for_alphalens = alphalens.utils.get_clean_factor(factor_to_evaluate, pd.DataFrame(forward_returns), max_loss=0.9) \n",
    "\n",
    "    data_for_alphalens = data_for_alphalens.reset_index()\n",
    "    data_for_alphalens['date'] = pd.to_datetime(data_for_alphalens['date'])  ### make sure the dtype of date column\n",
    "    data_for_alphalens.columns = ['date', 'asset'] + list(data_for_alphalens.columns[2:])\n",
    "    data_for_alphalens = data_for_alphalens.set_index(['date', 'asset'])\n",
    "    data_for_alphalens.columns = ['21D'] + list(data_for_alphalens.columns[1:])  ### alphalens only take standard column names\n",
    "    # data_for_alphalens.columns = forward_returns_cols + list(data_for_alphalens.columns[1:])  ### alphalens only take standard column names\n",
    "\n",
    "#     alphalens.tears.create_returns_tear_sheet(data_for_alphalens)\n",
    "\n",
    "#     alphalens.tears.create_information_tear_sheet(\n",
    "#         factor_data=data_for_alphalens, group_neutral=False, by_group=False, set_context=False\n",
    "#     )\n",
    "\n",
    "#     alphalens.plotting.plot_quantile_statistics_table(data_for_alphalens)\n",
    "\n",
    "    alphalens.tears.create_full_tear_sheet(data_for_alphalens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_single(b):\n",
    "    '''Make widgets for single model.'''\n",
    "    clear_output()\n",
    "    display(individual_eval_button)\n",
    "    global factor_select, target_select, ticker_select, run_eval_button\n",
    "    factor_select = Dropdown(options=all_factors, height='30px', margin=leftm(), width='200px')\n",
    "    target_select = Dropdown(options=all_factors, height='30px', margin=leftm(), width='200px')\n",
    "    tickers_options = ['cross_tickers'] + all_tickers\n",
    "    ticker_select = Dropdown(options=tickers_options, height='30px', margin=leftm(), width='200px')\n",
    "    \n",
    "    rows = []\n",
    "    rows.append(Box([Label('Independent Factor: ', layout=Layout(width='200px')), factor_select], layout=row_layout))\n",
    "    rows.append(Box([Label('Target Variable: ', layout=Layout(width='200px')), target_select], layout=row_layout))\n",
    "    rows.append(Box([Label('Ticker Only: ', layout=Layout(width='200px')), ticker_select], layout=row_layout))\n",
    "\n",
    "    result = Box(rows, layout=Layout(**col_layout))\n",
    "    display(result)\n",
    "    \n",
    "    run_eval_button = Button(description=\"Run_Evaluation\", button_style='success', margin=leftm(650))\n",
    "    display(run_eval_button)\n",
    "    run_eval_button.on_click(run_single_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdbda14b8e4445fa75423396c868449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Individual_Evaluation', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "individual_eval_button = Button(description=\"Individual_Evaluation\", button_style='success', margin=leftm(650))\n",
    "display(individual_eval_button)\n",
    "individual_eval_button.on_click(alpha_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override ipythonwidgets build in function\n",
    "def _get_min_max_value(min, max, value=None, step=None):\n",
    "    \"\"\"Return min, max, value given input values with possible None.\"\"\"\n",
    "    if value is None:\n",
    "        if not max > min:\n",
    "            raise ValueError('max must be greater than min: (min={0}, max={1})'.format(min, max))\n",
    "        diff = max - min\n",
    "        value = min + (diff / 2)\n",
    "        # Ensure that value has the same type as diff\n",
    "        if not isinstance(value, type(diff)):\n",
    "            value = min + (diff // 2)\n",
    "    elif min is None and max is None:\n",
    "        if not value:\n",
    "            t = type(value)\n",
    "            min, max = (t(0), t(1))\n",
    "        elif value > 0:\n",
    "            min, max = (0, np.max([10*value, 10]))\n",
    "        else:\n",
    "            min, max = (np.min([10*value, -10]), 0)\n",
    "    else:\n",
    "        raise ValueError('unable to infer range, value from: ({0}, {1}, {2})'.format(min, max, value))\n",
    "    if step is not None:\n",
    "        # ensure value is on a step\n",
    "        r = (value - min) % step\n",
    "        value = value - r\n",
    "    return min, max, value\n",
    "\n",
    "interaction._get_min_max_value = _get_min_max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run single model\n",
    "model_options = {'LinearRegression': 'ols',\n",
    "            'Ridge': 'ridge',\n",
    "            'Lasso': 'lasso',\n",
    "            'ElasticNet': 'enet',\n",
    "            'BayesianRidge': 'bayes',\n",
    "            'SVR': 'svr',\n",
    "            'KNeighborsRegressor': 'knnrgr',\n",
    "            'DecisionTreeRegressor': 'dtrgr',\n",
    "            'AdaBoostRegressor': 'ab',\n",
    "            'GradientBoostingRegressor': 'gbrgr',\n",
    "            'RandomForestRegressor': 'rfrgr',\n",
    "            'ExtraTreesRegressor': 'ert',\n",
    "            'BaggingRegressor': 'bag',\n",
    "            'XgBoost': 'xgboost'}\n",
    "\n",
    "model_args = {\n",
    "    'ols': {'fit_intercept': True, 'normalize': False, 'n_jobs': 1},\n",
    "    'ridge': {'alpha': 1.0, 'fit_intercept': True, 'normalize': False},\n",
    "    'lasso': {'alpha': 1.0, 'fit_intercept': True, 'normalize': False},\n",
    "    'enet': {'alpha':1.0, 'l1_ratio': 0.5, 'fit_intercept': True, 'normalize': False},\n",
    "    'bayes': {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'lambda_1': 1e-06, 'lambda_2': 1e-06, \n",
    "              'compute_score': False, 'fit_intercept': True, 'normalize': False},\n",
    "    'svr': {'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'], 'degree': 3,\n",
    "            'gamma': 'auto', 'coef0': 0.0, 'C': 1.0, 'epsilon': 0.1,'shrinking': True},\n",
    "    'knnrgr': {'n_neighbors': 5, 'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'leaf_size': 30, 'p': 2, 'metric': 'minkowski', 'n_jobs': 1},\n",
    "    'dtrgr': {'criterion': 'mse', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10,\n",
    "           'min_samples_leaf': 15, 'min_weight_fraction_leaf': 0.0},\n",
    "    'ab': {'n_estimators': 50, 'learning_rate': 1.0, 'loss': 'linear'},\n",
    "    'gbrgr': {'loss': 'ls', 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0,\n",
    "           'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0,\n",
    "           'max_depth': 3, 'alpha': 0.9},\n",
    "    'rfrgr': {'n_estimators': 10, 'criterion': 'mse', 'max_depth': 20, 'min_samples_split': 2,\n",
    "           'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto',\n",
    "           'bootstrap': True, 'oob_score': False, 'n_jobs': 1},\n",
    "    'ert': {'n_estimators': 10, 'criterion': 'mse', 'max_depth': 20, 'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto',\n",
    "            'bootstrap': False, 'oob_score': False, 'n_jobs': 1},\n",
    "    'bag': {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True,\n",
    "            'bootstrap_features': False, 'oob_score': False, 'n_jobs': 1},\n",
    "    'xgboost': {'n_estimators': 200, 'max_depth': 7, 'eta': 0.1, 'subsample': 0.7,\n",
    "            'colsample_bytree': 0.8}}\n",
    "\n",
    "metric_options = {'R2 Score': 'r2', 'Mean Squared Error': 'mse', 'Mean Absolute Error': 'mae', \n",
    "                  'Median Absolute Error': 'meae', 'Explained Variance Score': 'evs'}\n",
    "\n",
    "# widgets\n",
    "model_dropcat = Checkbox(value=True, margin=leftm(), width='50px')\n",
    "model_dropthrh = IntSlider(value=500, max=500, margin=leftm())\n",
    "\n",
    "model_seed = IntText(value=0, width='150px', margin=leftm())\n",
    "model_split = FloatSlider(value=0.7, min=0, max=1, step=0.01, width='600px', margin=leftm())\n",
    "model_select = Dropdown(options=model_options, value='dtrgr', height='30px', margin=leftm(),\n",
    "                        width='200px')\n",
    "model_metric = SelectMultiple(options=metric_options, value=('r2',), height='90px', margin=leftm(),\n",
    "                              width='200px')\n",
    "model_prog = FloatProgress(value=0, min=0, max=10, step=1, description='Progress:',\n",
    "                           margin=leftm(600), width='200px')\n",
    "modelb = Button(description=\"Run Model\", button_style='success', width='100px', margin=leftm(150))\n",
    "modelb_rolling = Button(description=\"Run Model\", button_style='success', width='100px', margin=leftm(150))\n",
    "model_save = Button(description=\"Save Results\", button_style='warning', width='100px', margin=leftm(150))\n",
    "\n",
    "def make_single():\n",
    "    '''Make widgets for single model.'''\n",
    "    global model_target, model_features, selection_range_slider\n",
    "    ### kai test for time range\n",
    "    all_dates = list(dsData.data['date'].sort_values())\n",
    "    minimum_date, max_date = all_dates[0], all_dates[-1]\n",
    "    start_date, end_date = pd.to_datetime(minimum_date), pd.to_datetime(max_date)\n",
    "    dates = pd.date_range(start_date, end_date, freq='D')\n",
    "    options = [(date.strftime('%d%b%Y'), date) for date in dates]\n",
    "    index = (0, len(options)-1)\n",
    "    selection_range_slider = widgets.SelectionRangeSlider(\n",
    "        options=options,\n",
    "        index=index,\n",
    "        description='Dates',\n",
    "        orientation='horizontal',\n",
    "        layout={'width': '500px'}\n",
    "    )\n",
    "    ### kai test for time range\n",
    "    model_obj.define_regressor(model_name=model_select.value, **model_args[model_select.value])\n",
    "    print(model_obj.model)\n",
    "    model_target = Dropdown(options=dsData.get_header(['float', 'int'], sort=True), height='30px',\n",
    "                            margin=leftm(), width='200px')\n",
    "    columns = dsData.get_header(['float', 'int', 'category', 'object'], sort=True)\n",
    "    features_height = np.min([300, np.max([len(columns) * 12, 100])])\n",
    "    model_features = SelectMultiple(options=columns, margin=leftm(),\n",
    "                                    height='{}px'.format(features_height))\n",
    "    rows = []\n",
    "    rows.append(Box([Label('Insample Date Range: ', layout=Layout(width='200px')), selection_range_slider], layout=row_layout))\n",
    "    rows.append(Box([Label('Target Variable: ', layout=Layout(width='200px')), model_target], layout=row_layout))\n",
    "    rows.append(Box([Label('Independent Variables: ', layout=Layout(width='200px')), model_features], layout=row_layout))\n",
    "    rows.append(Box([Label('Evaluation Metric: ', layout=Layout(width='200px')), model_metric], layout=row_layout))\n",
    "    rows.append(Box([Label('Select Model: ', layout=Layout(width='200px')), model_select, model_save, modelb], layout=row_layout))\n",
    "    rows.append(Box([model_prog], layout=row_layout))\n",
    "    rows.append(Box([model_toggle_param], margin='0px 0px 20px 0px'))\n",
    "    return Box(rows, layout=Layout(**col_layout), height='{}px'.format(300 + features_height))\n",
    "\n",
    "# functions\n",
    "def model_chg(chg):\n",
    "    '''Listen to model change event, and re-define regressor and create model parameter Box.'''\n",
    "    global model_param_displayed, w\n",
    "#     clear_output()\n",
    "    w.close()\n",
    "    model_obj.define_regressor(model_name=model_select.value)\n",
    "    print(model_obj.model)\n",
    "    args = model_args[model_select.value]\n",
    "    w = interactive(set_params, **args)\n",
    "    w = modify_box_widget(w)\n",
    "    if model_param_displayed:\n",
    "        display(w)\n",
    "\n",
    "def set_params(**args):\n",
    "    '''Set model parameters and print.'''\n",
    "    model_obj.model.set_params(**args)\n",
    "    print(model_obj.model)\n",
    "\n",
    "def modify_box_widget(w):\n",
    "    '''Modify the model parameter box widget.'''\n",
    "    children = []\n",
    "    for child in w.children:\n",
    "        child.margin = leftm()\n",
    "        if hasattr(child, 'description'):\n",
    "            desc = child.description\n",
    "            child.description = ''\n",
    "            children.append(Box([Label('{}: '.format(desc), layout=Layout(width='200px')), child], layout=row_layout))\n",
    "        else:\n",
    "            children.append(child)\n",
    "    return Box(children, layout=Layout(**col_layout), height='{}px'.format(40 * len(w.children)))\n",
    "\n",
    "model_select.observe(model_chg, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Rolling Models\n",
    "# widgets\n",
    "# model_select2 = SelectMultiple(options=model_options, height='200px', margin=leftm(),\n",
    "#                                width='200px')\n",
    "model_select2 = Dropdown(options=model_options, value='dtrgr', height='30px', margin=leftm(),\n",
    "                        width='200px')\n",
    "\n",
    "model_metric2 = Dropdown(options=metric_options, value='r2', height='30px', margin=leftm(),\n",
    "                         width='200px')\n",
    "\n",
    "model_toggle_param = Button(description=\"Toggle Model Settings\", button_style='success',\n",
    "                            width='170px')\n",
    "    \n",
    "def make_rolling():\n",
    "    '''Make widgets for multiple models'''\n",
    "    global model_target, model_features, rolling_selection_range_slider\n",
    "    #model_obj.define_regressor(model_name='all')\n",
    "#     model_obj.define_regressor(model_name='run_all_regressors')\n",
    "\n",
    "#     model_select2_value = \"dtrgr\" if model_select2.value == () else model_select2.value \n",
    "#     model_obj.define_regressor(model_name=model_select2_value, **model_args[model_select2_value])    \n",
    "    model_obj.define_regressor(model_name=model_select2.value, **model_args[model_select2.value])\n",
    "\n",
    "    model_target = Dropdown(options=dsData.get_header(['float', 'int'], sort=True), height='30px',\n",
    "                            margin=leftm(), width='200px')\n",
    "    columns = dsData.get_header(['float', 'int', 'category', 'object'], sort=True)\n",
    "    features_height = np.min([300, np.max([len(columns) * 12, 100])])\n",
    "    model_features = SelectMultiple(options=columns, margin=leftm(),\n",
    "                                    height='{}px'.format(features_height))\n",
    "    \n",
    "    \n",
    "    all_dates = list(dsData.data['date'].sort_values())\n",
    "    minimum_date, max_date = all_dates[0], all_dates[-1]\n",
    "    start_date, end_date = pd.to_datetime(minimum_date), pd.to_datetime(max_date)\n",
    "    dates = pd.date_range(start_date, end_date, freq='D')\n",
    "    options = [(date.strftime('%d%b%Y'), date) for date in dates]\n",
    "    index = (0, len(options)-1)    \n",
    "    \n",
    "    rolling_selection_range_slider = widgets.SelectionRangeSlider(\n",
    "        options=options,\n",
    "        index=index,\n",
    "        description='Dates',\n",
    "        orientation='horizontal',\n",
    "        layout={'width': '500px'}\n",
    "    )\n",
    "    rows = []\n",
    "    rows.append(Box([Label('Insample Date Range: ', layout=Layout(width='200px')), rolling_selection_range_slider], layout=row_layout))\n",
    "    rows.append(Box([Label('Target Variable: ', layout=Layout(width='200px')), model_target], layout=row_layout))\n",
    "    rows.append(Box([Label('Independent Variables: ', layout=Layout(width='200px')), model_features], layout=row_layout))\n",
    "    rows.append(Box([Label('Evaluation Metric: ', layout=Layout(width='200px')), model_metric2], layout=row_layout))\n",
    "    rows.append(Box([Label('Select Models: ', layout=Layout(width='200px')), model_select2], layout=row_layout))\n",
    "    rows.append(Box([modelb_rolling], margin=leftm(500)))\n",
    "    rows.append(Box([model_prog], layout=row_layout))\n",
    "    rows.append(model_toggle_param)\n",
    "    return Box(rows, layout=Layout(**col_layout), height='{}px'.format(450 + features_height))\n",
    "\n",
    "# functions\n",
    "model_param_displayed = False\n",
    "def toggle_param(b):\n",
    "    '''Toggle model parameters.'''\n",
    "    global model_param_displayed, w\n",
    "    if model_param_displayed:\n",
    "        w.close()\n",
    "    else:\n",
    "        if mode_select.value == 'Run Single Model':\n",
    "            args = model_args[model_select.value]\n",
    "            w = interactive(set_params, **args)\n",
    "            w = modify_box_widget(w)\n",
    "        else:\n",
    "            w = get_multiple_params()\n",
    "        display(w)\n",
    "    model_param_displayed = not model_param_displayed\n",
    "\n",
    "def get_multiple_params():\n",
    "    '''Create parameter Box for multiple models.'''\n",
    "    rows = []\n",
    "    for model in model_select2.value:\n",
    "        args = model_args[model]\n",
    "        w = interactive(set_params_model, model=fixed(model), **args)\n",
    "        w = modify_box_widget(w)\n",
    "        name = re.match('(\\w+)\\(' , str(model_obj.models[model])).group(1)\n",
    "        rows.append(HTML('<b>{}</b>'.format(name), margin='20px 0px 10px 0px'))\n",
    "        rows.append(w)\n",
    "    return VBox(rows)\n",
    "\n",
    "def set_params_model(model, **args):\n",
    "    '''Set parameters for a specific model and print.'''\n",
    "    model_obj.models[model].set_params(**args)\n",
    "    print(model_obj.models[model])\n",
    "\n",
    "model_toggle_param.on_click(toggle_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one_run(insample_data, outsample_data, features, insample_end_date):\n",
    "    XX_train, yy_train = insample_data[list(model_features.value)], insample_data[model_target.value]\n",
    "    XX_test, yy_test = outsample_data[list(model_features.value)], outsample_data[model_target.value]\n",
    "    XX_test = XX_test.head(2)\n",
    "\n",
    "    ### always use sklearn linear models to run, even after statsmodels approach        \n",
    "    model_obj.fit_model(XX_train, yy_train, indep_cols=features) \n",
    "    yy_test_predicted = model_obj.predict(XX_test)\n",
    "    yy_test, yy_test_predicted = yy_test.head(1), yy_test_predicted.head(1)\n",
    "    yy_test.index = [insample_end_date]*yy_test.shape[0]\n",
    "    yy_test_predicted.index = [insample_end_date]*yy_test_predicted.shape[0]\n",
    "    yy_test_compare_piece = pd.concat([yy_test.T, yy_test_predicted.T]).T\n",
    "    return yy_test_compare_piece\n",
    "    \n",
    "    \n",
    "def rolling_compare(yy_test_compare_list, all_data_dates):\n",
    "    y_rolling_compare = pd.concat(yy_test_compare_list)\n",
    "    y_rolling_compare.columns = [\"True\", \"Predicted\"]\n",
    "    y_rolling_compare = y_rolling_compare.loc[[(j in all_data_dates) for j in y_rolling_compare.index]]\n",
    "    return y_rolling_compare\n",
    "\n",
    "    \n",
    "def run_rolling_model(b):\n",
    "    if len(model_features.value) == 0:\n",
    "        raise ValueError(\"Please select independent variables.\")\n",
    "    \n",
    "    model_prog.value = 0\n",
    "    model_prog.description = 'Start...'\n",
    "    features = list(np.setdiff1d(model_features.value, [model_target.value]))\n",
    "    all_cols = features + [model_target.value]\n",
    "    dsData.create_dummy_data(features)\n",
    "    \n",
    "    global y_rolling_compare\n",
    "    y_rolling_true, y_rolling_predicted = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "\n",
    "    insample_start_date, insample_end_date = rolling_selection_range_slider.value[0], rolling_selection_range_slider.value[1]\n",
    "    all_data = dsData.data\n",
    "    all_data[\"date\"] = pd.to_datetime(all_data[\"date\"])\n",
    "    all_data_dates = all_data[\"date\"].values\n",
    "    step_size_days = 1\n",
    "    yy_test_compare_list = list()\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "#         print(count)\n",
    "        flg1 = [(j>=insample_start_date)&(j<=insample_end_date) for j in all_data[\"date\"]]\n",
    "        insample_data = all_data[flg1]\n",
    "        flg4 = [(j>insample_end_date) for j in all_data[\"date\"]]\n",
    "        outsample_data = all_data[flg4]\n",
    "        if insample_data.shape[0] < 1 or outsample_data.shape[0] < 1:\n",
    "            break\n",
    "        cur_yy_test_compare_piece = delayed(model_one_run)(insample_data, outsample_data, features, insample_end_date)\n",
    "#         cur_yy_test_compare_piece = model_one_run(insample_data, outsample_data, features, insample_end_date)\n",
    "        yy_test_compare_list.append(cur_yy_test_compare_piece)\n",
    "        insample_start_date, insample_end_date = insample_start_date + pd.Timedelta(days=step_size_days), insample_end_date + pd.Timedelta(days=step_size_days)\n",
    "        count += 1\n",
    "        \n",
    "    total = delayed(rolling_compare)(yy_test_compare_list, all_data_dates)\n",
    "    y_rolling_compare = total.compute()\n",
    "\n",
    "#     y_rolling_compare = rolling_compare(yy_test_compare_list, all_data_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_model(b):\n",
    "    if len(model_features.value) == 0:\n",
    "        raise ValueError(\"Please select independent variables.\")\n",
    "    \n",
    "    model_prog.value = 0\n",
    "    model_prog.description = 'Start...'\n",
    "    features = list(np.setdiff1d(model_features.value, [model_target.value]))\n",
    "    all_cols = features + [model_target.value]\n",
    "    dsData.create_dummy_data(features)\n",
    "    \n",
    "    global XX_train, yy_train, XX_test, yy_test\n",
    "    \n",
    "    ### kai test\n",
    "    insample_start_date, insample_end_date = selection_range_slider.value[0], selection_range_slider.value[1]\n",
    "    all_data = dsData.data\n",
    "    all_data[\"date\"] = pd.to_datetime(all_data[\"date\"])\n",
    "    flg1 = [(j>=insample_start_date) for j in all_data[\"date\"]]\n",
    "    insample_data = all_data[flg1]\n",
    "    flg2 = [(j<=insample_end_date) for j in insample_data[\"date\"]]\n",
    "    insample_data = insample_data[flg2]\n",
    "\n",
    "    flg3 = [(j<insample_start_date) for j in all_data[\"date\"]]\n",
    "    outsample_data_1 = all_data[flg3]\n",
    "    flg4 = [(j>insample_end_date) for j in all_data[\"date\"]]\n",
    "    outsample_data_2 = all_data[flg4]\n",
    "    outsample_data = pd.concat([outsample_data_1, outsample_data_2])\n",
    "\n",
    "    XX_train, yy_train = insample_data[list(model_features.value)], insample_data[model_target.value]\n",
    "    XX_test, yy_test = outsample_data[list(model_features.value)], outsample_data[model_target.value]\n",
    "    # insample_data = all_data.loc[(all_data[\"date\"]>start_date) & (all_data[\"date\"]<end_date)]\n",
    "    ### kai test\n",
    "\n",
    "    if mode_select.value == 'Run Single Model':\n",
    "        global stats_model\n",
    "        if model_select.value == 'ols':\n",
    "            X, Y = XX_train.copy(deep=True), yy_train.copy(deep=True)\n",
    "            X = sm_api.add_constant(X)\n",
    "            stats_model = sm_api.OLS(Y, X).fit() \n",
    "        elif model_select.value in 'ridge':      \n",
    "            X, Y = XX_train.copy(deep=True), yy_train.copy(deep=True)\n",
    "            scaler = StandardScaler(with_mean=False)\n",
    "            X_scaled = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "            stats_model = sm_api.OLS(Y, X_scaled).fit_regularized(method='elastic_net', alpha=penalty, L1_wt=0)              \n",
    "        elif model_select.value in 'lasso':      \n",
    "            X, Y = XX_train.copy(deep=True), yy_train.copy(deep=True)            \n",
    "            scaler = StandardScaler(with_mean=False)\n",
    "            X_scaled = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "            stats_model = sm_api.OLS(Y, X_scaled).fit_regularized(method='elastic_net', alpha=penalty, L1_wt=1)\n",
    "            \n",
    "        ### still use sklearn linear models to run, even after statsmodels approach        \n",
    "        model_obj.fit_model(XX_train, yy_train, indep_cols=features) \n",
    "        pred_name = \"predicted_\" + model_target.value\n",
    "        dsData.data[pred_name] = model_obj.predict(dsData.dummies)\n",
    "        pred_error_name = \"error_predicted_\" + model_target.value\n",
    "        dsData.data[pred_error_name] = model_obj.predict(dsData.dummies) - dsData.data[model_target.value]\n",
    "        model_prog.value = 5\n",
    "        model_prog.description = 'Progress.'\n",
    "        model_prog.description = 'Done!'\n",
    "        model_prog.value = 10\n",
    "    else:\n",
    "        model_prog.value = 5\n",
    "        model_prog.description = 'Progress.'\n",
    "        res = model_obj.model_comparison(XX_train, yy_train, XX_test, yy_test, features,\n",
    "                                   list(model_select2.value))\n",
    "        res = pd.Series(res).reset_index().round(4)\n",
    "        res.columns = ['Model', model_metric2.value]\n",
    "        res.sort_values(model_metric2.value, ascending=False, inplace=True)\n",
    "        print('\\nModel Performance')\n",
    "        display(res)\n",
    "        model_prog.description = 'Done!'\n",
    "        model_prog.value = 10\n",
    "\n",
    "\n",
    "def show_results(X_train, y_train, X_test, y_test):\n",
    "    '''Show prediction results and performance scores.'''\n",
    "    global train_scores, test_scores, fi, coef \n",
    "    # performance score\n",
    "    print(\"performance score\")\n",
    "    print(\"On Training Set\")\n",
    "    pred_train = model_obj.predict(X_train)\n",
    "    train_scores = model_obj.eval_model(ytrue=y_train, ypred=pred_train, metric_list=model_metric.value)\n",
    "    train_scores = pd.DataFrame({'metric': model_metric.value, 'score': train_scores}).round(4)\n",
    "    display(train_scores)\n",
    "\n",
    "    print(\"On Testing Set\")\n",
    "    pred_test = model_obj.predict(X_test)\n",
    "    test_scores = model_obj.eval_model(ytrue=y_test, ypred=pred_test, metric_list=model_metric.value)\n",
    "    test_scores = pd.DataFrame({'metric': model_metric.value, 'score': test_scores}).round(4)\n",
    "    display(test_scores)\n",
    "\n",
    "    if hasattr(model_obj.model, 'feature_importances_'):\n",
    "        fi = model_obj.check_feature_importance(group=True).round(4)\n",
    "        print('\\nFeature Importance')\n",
    "        display(fi)\n",
    "\n",
    "    if model_select.value == 'dtrgr':\n",
    "       img_bi = model_obj.decision_tree_plot()\n",
    "       display(SVG(img_bi))\n",
    "\n",
    "    if model_select.value == 'ols':\n",
    "        coef = pd.DataFrame({'Feature': model_obj.dummy_indep_cols, 'Coef': model_obj.model.coef_})\n",
    "        pos_mask = coef['Coef'] > 0\n",
    "        pos_coef = coef[pos_mask].sort_values('Coef', ascending=False)\n",
    "        neg_coef = coef[~pos_mask].sort_values('Coef')\n",
    "        display('Positive Coefficients', pos_coef)\n",
    "        display('Negative Coefficients', neg_coef)\n",
    "        print(model_obj)\n",
    "        print(model_obj.model)\n",
    "        \n",
    "        model_summary = stats_model.summary()\n",
    "        display(model_summary)\n",
    "\n",
    "    # make prediction\n",
    "    print(\"Predictions on Test Data\")\n",
    "#     display(pd.concat([pred_test, y_test, dsData.data.ix[y_test.index, model_obj.indep_cols]], axis=1))\n",
    "    display(pd.concat([pred_test, y_test, dsData.data.loc[y_test.index, model_obj.indep_cols]], axis=1))\n",
    "\n",
    "def save_results(b):\n",
    "    try:\n",
    "        if not os.path.exists('results'):\n",
    "            os.makedirs('results')\n",
    "        train_scores.to_csv('results/train_scores.csv', index=False)\n",
    "        test_scores.to_csv('results/test_scores.csv', index=False)\n",
    "        fi.to_csv('results/feature_importance,csv', index=False)\n",
    "        if model_select.value == 'ols':\n",
    "            coef.to_csv('results/coefficients.csv')\n",
    "        elif model_select.value == 'dtrgr':\n",
    "            png = model_obj.decision_tree_plot('png')\n",
    "            with open('results/decision_tree_plot.png', 'wb') as f:\n",
    "                f.write(png)\n",
    "        print('Done!')\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "modelb.on_click(run_model)\n",
    "modelb_rolling.on_click(run_rolling_model)\n",
    "model_save.on_click(save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143c703e3e114bf9afae05e1d4e93654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Mode: '), ToggleButtons(index=1, options=('Run Single Model', 'Run Rolling Models'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e4a19044184ed2aa2dc5e3833f2c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(Label(value='Insample Date Range: ', layout=Layout(width='200px')), SelectionRangeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "# Select Mode\n",
    "mode_select = ToggleButtons(options=['Run Single Model', 'Run Rolling Models'], value='Run Single Model', margin=leftm())\n",
    "\n",
    "display(HBox([Label('Mode: '), mode_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "mode_mapping = {'Run Single Model': make_single, 'Run Rolling Models': make_rolling}\n",
    "mode = HTML('')\n",
    "w = HTML('')\n",
    "\n",
    "rows = []\n",
    "rows.append(Box([Label('Drop Categorical Column if Too Many Distinct Values: ', layout=Layout(width='600px')), model_dropcat,\n",
    "                 Label('Threshold: '), model_dropthrh], layout=row_layout))\n",
    "rows.append(Box([Label('Random Seed: ', layout=Layout(width='200px')), model_seed], layout=row_layout))\n",
    "rows.append(Box([Label('Proportion for Training: ', layout=Layout(width='200px')), model_split], layout=row_layout))\n",
    "\n",
    "display(Box(rows, layout=Layout(**col_layout), height='120px', margin='0px 0px 10px 0px'))\n",
    "\n",
    "def switch_mode(chg):\n",
    "    '''Switch between modeling mode.'''\n",
    "    global mode\n",
    "    clear_output()\n",
    "\n",
    "    mode.close()\n",
    "    mode = mode_mapping[mode_select.value]()\n",
    "    display(HBox([Label('Mode: '), mode_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "    display(mode)\n",
    "\n",
    "mode_select.observe(switch_mode, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## to delete\n",
    "# ### kai test\n",
    "\n",
    "# insample_start_date, insample_end_date = selection_range_slider.value[0], selection_range_slider.value[1]\n",
    "# all_data = dsData.data\n",
    "# all_data[\"date\"] = pd.to_datetime(all_data[\"date\"])\n",
    "\n",
    "# step_size_days = 1\n",
    "# insample_start_date, insample_end_date = insample_start_date + pd.Timedelta(days=step_size_days), insample_end_date + pd.Timedelta(days=step_size_days)\n",
    "# flg1 = [(j>=insample_start_date)&(j<=insample_end_date) for j in all_data[\"date\"]]\n",
    "# ## if shift flg1 forward 1\n",
    "# # flg1 = [False] + flg1[:(-1)]\n",
    "# insample_data = all_data[flg1]\n",
    "# # flg2 = [(j<=insample_end_date) for j in insample_data[\"date\"]]\n",
    "# # insample_data = insample_data[flg2]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Result (only for single model)\n",
    "- model result in testing data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa4842ac02427f9f37df51cdf2c106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Model Result Type: ', layout=Layout(width='200px')), ToggleButtons(options=('Visuaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select Graph\n",
    "\n",
    "# widgets\n",
    "Result_chart_select = ToggleButtons(\n",
    "    options=['Visualize Prediction', 'Display Predictions'],\n",
    "    tooltips=['Visualize Prediction outside training set, Confidence Interval and real values', 'Display Predictions'],\n",
    "    value='Visualize Prediction', \n",
    "    margin=leftm()\n",
    ")\n",
    "\n",
    "display(HBox([Label('Model Result Type: ', layout=Layout(width='200px')), Result_chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "# functions\n",
    "grph = HTML('')\n",
    "\n",
    "def Result_switch_chart(chg):\n",
    "    '''Switch between graph type.'''\n",
    "    global grph\n",
    "    clear_output()\n",
    "    display(HBox([Label('Model Result Type: ', layout=Layout(width='200px')), Result_chart_select], layout=Layout(margin='0px 0px 30px 0px')))\n",
    "\n",
    "    if (grph != None):\n",
    "        grph.close()\n",
    "    #grph.close()\n",
    "    grph = Result_graph_mapping[Result_chart_select.value]()\n",
    "    display(grph)\n",
    "\n",
    "Result_chart_select.observe(Result_switch_chart, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Interval chart\n",
    "# widgets\n",
    "def make_Confidence_Interval():\n",
    "    '''create widgets for Confidence_Interval'''\n",
    "    #global pie_filter2, pie_select2, pie_limit2, group_less_freq2, pieb2\n",
    "    global pie_select2, pieb2\n",
    "    #pie_filter2 = Text(value='', width='500px')\n",
    "    pie_select2 = Dropdown(options=dsData.get_header(sort=True), height='30px', width='200px',\n",
    "                          margin=leftm())\n",
    "    #pie_limit2 = IntText(value=20, width='70px')\n",
    "    #group_less_freq2 = Checkbox(value=False)\n",
    "    pieb2 = Button(description=\"Plot\", button_style='success', width='70px', height='30px',\n",
    "                  margin=leftm(20))\n",
    "    row0 = Box([HTML('<h4> Visualize outsample prediction and confidence interval</h4>')],\n",
    "                layout=Layout(display='flex', flex_flow='row', align_items='center',\n",
    "                              justify_content='center', width='90%'))\n",
    "    row1 = Box([pieb2], layout=row_layout)\n",
    "    scatter_chart = Box([row0, row1], layout=Layout(**col_layout),\n",
    "                    height='160px')\n",
    "    pie_select2.observe(plot_Confidence_Interval, names='value')\n",
    "    pieb2.on_click(plot_Confidence_Interval)\n",
    "    return scatter_chart\n",
    "\n",
    "# functions\n",
    "def gradientBoostingRegr_band(clf_outside, X_train, y_train, X_test, y_test):\n",
    "    '''clf must be gradient boosting regressor'''\n",
    "    ## for upper bound\n",
    "    clf = clone(clf_outside)\n",
    "    alpha = 0.95\n",
    "    clf.set_params(loss='quantile')\n",
    "    clf.set_params(alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_upper = clf.predict(X_test)\n",
    "    ## for lower bound\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_lower = clf.predict(X_test)\n",
    "    ## for prediction\n",
    "    clf.set_params(loss='ls')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, y_upper, y_lower\n",
    "    \n",
    "def plot_Confidence_Interval(chg):\n",
    "    '''plot the Confidence Interval chart'''\n",
    "    clear_output()\n",
    "    display(HBox([Label('Model Result Type: ', layout=Layout(width='200px')), \n",
    "                  Result_chart_select], layout=Layout(margin='0px 0px 30px 0px')))  ## kai test\n",
    "\n",
    "#     if ((type(model_obj.model) != sklearn.ensemble.forest.RandomForestRegressor) and (type(model_obj.model) != sklearn.ensemble.gradient_boosting.GradientBoostingRegressor)):\n",
    "#         return None\n",
    "    if ((type(model_obj.model) != sklearn.ensemble.RandomForestRegressor) and (type(model_obj.model) != sklearn.ensemble.GradientBoostingRegressor)):\n",
    "        return None    \n",
    "    \n",
    "    forest = model_obj.model\n",
    "\n",
    "    if (type(forest) == sklearn.ensemble.RandomForestRegressor):\n",
    "        #forest.fit(X_train, y_train)\n",
    "        y_hat = forest.predict(XX_test)\n",
    "        #V_IJ_calibrated = fci.random_forest_error(forest,X_train, X_test)\n",
    "        V_IJ_calibrated = random_forest_error(forest,XX_train, XX_test)\n",
    "\n",
    "        yerr=np.sqrt(V_IJ_calibrated)\n",
    "        y_mid = y_hat\n",
    "\n",
    "    if (type(forest) == sklearn.ensemble.GradientBoostingRegressor):\n",
    "        y_hat, y_upper, y_lower = gradientBoostingRegr_band(clf_outside=model_obj.model, X_train=XX_train, \n",
    "                                                            y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "        y_mid = 0.5 * (y_upper + y_lower)\n",
    "        yerr = y_upper - y_mid\n",
    "            \n",
    "    confidence_band = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(y_mid),\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    array=list(yerr),\n",
    "                    visible=True\n",
    "                ),\n",
    "                mode='markers',\n",
    "                name='confidence_band'\n",
    "            )\n",
    "\n",
    "    real_value = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(yy_test),\n",
    "                mode='markers',\n",
    "                name='real_value'\n",
    "            )\n",
    "    \n",
    "    prediction = go.Scatter(\n",
    "                x=list(yy_test),\n",
    "                y=list(y_hat),\n",
    "                mode='markers',\n",
    "                name='prediction'\n",
    "            )\n",
    "        \n",
    "    data = [confidence_band, real_value, prediction]\n",
    "    \n",
    "    layout = go.Layout(xaxis=dict(title='ytest'),\n",
    "                   yaxis=dict(title='ypred')\n",
    "                   )\n",
    "\n",
    "    figp = go.Figure(data=data, layout=layout)\n",
    "    #figp = go.Figure(data=[trace0, trace1, fx, observations], layout=layout)\n",
    "    \n",
    "    iplot(figp)\n",
    "#     logger.info('plotted Confidence Interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions_on_test():    \n",
    "    # make prediction\n",
    "    #print(\"Predictions on Test Data\")\n",
    "    forest = model_obj.model\n",
    "    #X_train, y_train, X_test, y_test = \\\n",
    "    #    model_obj.split_random(mld.dummies, mld.data[model_target.value],\n",
    "    #                     train_ratio=model_split.value)\n",
    "    \n",
    "    #show_results(X_train=XX_train, y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "    \n",
    "    try:\n",
    "        show_results(X_train=XX_train, y_train=yy_train, X_test=XX_test, y_test=yy_test)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "#         print(\"Capture error: need to run model first, and Graphviz executables are on your systems' path\")\n",
    "    #display(pd.concat([pred_test, y_test, mld.data.ix[y_test.index, model_obj.indep_cols]], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_graph_mapping = {'Visualize Prediction': make_Confidence_Interval, 'Display Predictions': display_predictions_on_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_YoY(data, target):\n",
    "#     '''expect self.data has columns date, sid, and the feature column to work on'''\n",
    "#     df = data.copy()\n",
    "#     df['date'] = pd.to_datetime(df['date'])\n",
    "#     delta_1yr_left, delta_1yr_right = pd.to_timedelta(395, 'd'), pd.to_timedelta(365, 'd')\n",
    "#     df[\"date_1yr_lag_left\"], df[\"date_1yr_lag_right\"] = (df['date'] - delta_1yr_left), (df['date'] - delta_1yr_right)\n",
    "\n",
    "#     def each_row(x, target=target):\n",
    "#         left_date, right_date = x['date_1yr_lag_left'], x['date_1yr_lag_right']\n",
    "#         filter_df = df[(df['date'] > left_date) & (df['date'] < right_date)]\n",
    "#         if filter_df.shape[0]<1:\n",
    "#             return(np.nan)            \n",
    "#         kpi_current, kpi_prev = x[target], filter_df.tail(1).squeeze()[target]\n",
    "#         try:\n",
    "#             return(kpi_current/kpi_prev - 1)\n",
    "#         except:\n",
    "#             return(np.nan)\n",
    "#     result = df.apply(lambda x : each_row(x, target=target), axis=1)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### temporary\n",
    "# this_feature = 'transactions'\n",
    "\n",
    "# data_with_features = dsData.data.copy()\n",
    "# cols = [this_feature+'$YoY', this_feature+'$QoQ', this_feature+'$QQYY']\n",
    "# for each_feature in cols:\n",
    "#     data_with_features[each_feature] = np.nan\n",
    "    \n",
    "    \n",
    "# univ_tickers = list(dsData.data['symbol'].unique())\n",
    "\n",
    "# for this_ticker in univ_tickers:\n",
    "#     data = dsData.data.copy()\n",
    "#     data = data[data['symbol']==this_ticker]\n",
    "\n",
    "#     ticker_MLdata = MLData()\n",
    "#     ticker_MLdata.data = data\n",
    "\n",
    "#     ticker_YoY = ticker_MLdata.calculate_YoY(this_feature)\n",
    "#     ticker_QoQ = ticker_MLdata.calculate_QoQ(this_feature)\n",
    "#     ticker_QQYY = ticker_MLdata.calculate_QQYY(this_feature)\n",
    "\n",
    "#     data[this_feature+'$YoY'] = ticker_YoY\n",
    "#     data[this_feature+'$QoQ'] = ticker_QoQ\n",
    "#     data[this_feature+'$QQYY'] = ticker_QQYY\n",
    "\n",
    "#     data_with_features.loc[data.index, cols] = data\n",
    "    \n",
    "# data_with_features.to_csv('fake_data.csv', index=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
