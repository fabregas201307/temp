{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "profile = 'crayon-site'\n",
    "region_name='us-east-2'\n",
    "bucket = 'st-crayon-dev'\n",
    "prefix = 'sagemaker/labelbox/'\n",
    "role = 'arn:aws:iam::395166463292:role/service-role/AmazonSageMaker-ExecutionRole-20200714T182988'\n",
    "\n",
    "from botocore.exceptions import ProfileNotFound\n",
    "\n",
    "try:\n",
    "    boto3.setup_default_session(profile_name=profile)\n",
    "except ProfileNotFound:\n",
    "    print(\"crayon-site profile not found. Using default aws profile.\")\n",
    "    \n",
    "\n",
    "session = boto3.session.Session(profile_name = profile, region_name = region_name)\n",
    "sess = sagemaker.Session(session,default_bucket=bucket)\n",
    "sagemaker_client = session.client('sagemaker')\n",
    "account_id = session.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'395166463292.dkr.ecr.us-east-2.amazonaws.com/ss-processing-container-v0:sitetools-test'"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "ecr_repository = 'ss-processing-container-v0'\n",
    "tag = ':sitetools-test'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region_name, ecr_repository + tag)\n",
    "processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creates an Amazon Elastic Container Registry (Amazon ECR) repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This step needs the aws cli installed locally, and sets up the repository to store the docker container to run the script processor with.\n",
    "\n",
    "NOTE: This only needs to be done once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nAn error occurred (UnrecognizedClientException) when calling the GetAuthorizationToken operation: The security token included in the request is invalid.\nError: Cannot perform an interactive login from a non TTY device\n\nAn error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'ss-processing-container-v0' already exists in the registry with id '395166463292'\n"
    }
   ],
   "source": [
    "!aws ecr get-login-password --region $region_name | docker login --username AWS --password-stdin \"{account_id}\".dkr.ecr.\"{region_name}\".amazonaws.com\n",
    "!aws ecr create-repository --repository-name $ecr_repository --profile $profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build the container using the docker command and Push to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Building the container and pushing into Amazon ECR.\n",
    "\n",
    "NOTE: This only needs to be done once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                                         \n\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.1s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.2s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.4s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.5s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.7s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  0.8s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.0s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.1s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (2/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.3s\n\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (3/3)                                                         \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.4s\n\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (10/11)                                                       \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.4s\n\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => CACHED [1/7] FROM docker.io/library/python:3.7-slim-buster@sha256:0e6  0.0s\n\u001b[0m\u001b[34m => CACHED [2/7] RUN apt-get -y update                                     0.0s\n\u001b[0m\u001b[34m => CACHED [3/7] RUN apt-get -y upgrade                                    0.0s\n\u001b[0m\u001b[34m => CACHED [4/7] RUN apt-get install -y libglib2.0-0 libsm6 libxext6 libx  0.0s\n\u001b[0m\u001b[34m => CACHED [5/7] RUN pip3 install pandas==0.25.3 scikit-learn==0.21.3 num  0.0s\n\u001b[0m\u001b[31m => ERROR [6/7] COPY ../../src/site_tools ./site_tools                     0.0s\n\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (10/11)                                                       \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.4s\n\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => CACHED [1/7] FROM docker.io/library/python:3.7-slim-buster@sha256:0e6  0.0s\n\u001b[0m\u001b[34m => CACHED [2/7] RUN apt-get -y update                                     0.0s\n\u001b[0m\u001b[34m => CACHED [3/7] RUN apt-get -y upgrade                                    0.0s\n\u001b[0m\u001b[34m => CACHED [4/7] RUN apt-get install -y libglib2.0-0 libsm6 libxext6 libx  0.0s\n\u001b[0m\u001b[34m => CACHED [5/7] RUN pip3 install pandas==0.25.3 scikit-learn==0.21.3 num  0.0s\n\u001b[0m\u001b[31m => ERROR [6/7] COPY ../../src/site_tools ./site_tools                     0.0s\n\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (10/11)                                                       \n\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n\u001b[0m\u001b[34m => => transferring dockerfile: 840B                                       0.0s\n\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/python:3.7-slim-buster  1.4s\n\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n\u001b[0m\u001b[34m => CACHED [1/7] FROM docker.io/library/python:3.7-slim-buster@sha256:0e6  0.0s\n\u001b[0m\u001b[33m => CANCELED [2/7] RUN apt-get -y update                                   0.3s\n\u001b[0m\u001b[34m => CACHED [3/7] RUN apt-get -y upgrade                                    0.0s\n\u001b[0m\u001b[34m => CACHED [4/7] RUN apt-get install -y libglib2.0-0 libsm6 libxext6 libx  0.0s\n\u001b[0m\u001b[34m => CACHED [5/7] RUN pip3 install pandas==0.25.3 scikit-learn==0.21.3 num  0.0s\n\u001b[0m\u001b[31m => ERROR [6/7] COPY ../../src/site_tools ./site_tools                     0.0s\n\u001b[0m\u001b[?25h------\n > [6/7] COPY ../../src/site_tools ./site_tools:\n------\nfailed to solve with frontend dockerfile.v0: failed to build LLB: failed to compute cache key: failed to walk /var/lib/docker/tmp/buildkit-mount058231380/src: lstat /var/lib/docker/tmp/buildkit-mount058231380/src: no such file or directory\n"
    }
   ],
   "source": [
    "!docker build -t $ecr_repository docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Error response from daemon: No such image: ss-processing-container-v0:sitetools-test\nThe push refers to repository [395166463292.dkr.ecr.us-east-2.amazonaws.com/ss-processing-container-v0]\n\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1B\n\u001b[1Bdenied: Your authorization token has expired. Reauthenticate and try again.\n"
    }
   ],
   "source": [
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set up the ScriptProcessor from the Amazon SageMaker Python SDK to run the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setup ScriptProcessor by pointing it to the docker container we created and specifying the instance count and type that it will run on. The `endpoint` is passed in as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'395166463292.dkr.ecr.us-east-2.amazonaws.com/ss-processing-container-v0:sitetools-test'"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "processing_repository_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                image_uri=processing_repository_uri,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.r5.large',\n",
    "                sagemaker_session=sess,\n",
    "                env={'endpoint':'endpointvalues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lss-all-ml-p2-xlarge\n"
    }
   ],
   "source": [
    "endpoints = sagemaker_client.list_endpoints()\n",
    "endpoint = endpoints['Endpoints'][0]['EndpointName']\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script in the docker container\n",
    "You can also use existing Docker images, including images that you run on other platforms, such Kubernetes.\n",
    "This will be output into the training folder as `output-1` for the script processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nJob Name:  ss-processing-container-v0-2020-09-04-16-14-02-338\nInputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://st-crayon-dev/data/raw/imgs/testing-single/', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://st-crayon-dev/ss-processing-container-v0-2020-09-04-16-14-02-338/input/code/inference_script.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\nOutputs:  [{'OutputName': 'output-1', 'S3Output': {'S3Uri': 's3://st-crayon-dev/data/raw/imgs/original/testing/anno_lss-all-ml-p2-xlarge-chip1024-crf-test', 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'Continuous'}}]\n........................\n..CPU times: user 834 ms, sys: 36.3 ms, total: 870 ms\nWall time: 4min 31s\n"
    }
   ],
   "source": [
    "%%time\n",
    "script_processor.run(\n",
    "    code=\"inference_script.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f\"s3://{bucket}/data/raw/imgs/testing-single/\",\n",
    "            destination=\"/opt/ml/processing/input/data\",\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output/train\", \n",
    "            destination=f\"s3://{bucket}/data/raw/imgs/original/testing/anno_{endpoint}-chip1024-crf-test\",\n",
    "            s3_upload_mode=\"Continuous\"),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"s3_input_bucket\",\n",
    "        bucket,\n",
    "        \"s3_input_key_prefix\",\n",
    "        prefix,\n",
    "        \"endpoint\",\n",
    "        endpoint,\n",
    "        \"chipsize\",\n",
    "        \"1024\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cli Commands\n",
    "```docker build -f notebooks/presentations/sagemaker-semantic-segmentation/docker/Dockerfile --tag 395166463292.dkr.ecr.us-east-2.amazonaws.com/ss-processing-container-v0:sitetools-test .``` \n",
    "<br>\n",
    "Log in \n",
    "<br>\n",
    "```aws ecr get-login-password --region us-east-2 --profile crayon-site | docker login --username AWS --password-stdin 395166463292.dkr.ecr.us-east-2.amazonaws.com``` \n",
    "<br>\n",
    "Create repo \n",
    "<br>\n",
    "```aws ecr create-repository --repository-name ss-processing-container-v0 --profile crayon-site```<br>\n",
    "<br>\n",
    "push image\n",
    "<br>\n",
    "```docker push 395166463292.dkr.ecr.us-east-2.amazonaws.com/ss-processing-container-v0:sitetools-test```\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}