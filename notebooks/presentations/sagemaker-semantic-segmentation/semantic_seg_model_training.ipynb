{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting. If you don't specify a bucket, SageMaker SDK will create a default bucket following a pre-defined naming convention in the same region.\n",
    "The IAM role ARN used to give SageMaker access to your data. It can be fetched using the get_execution_role method from sagemaker python SDK if running this notebook in sagemaker studio\n",
    "\n",
    "- profile = aws profile\n",
    "- role = predefined role arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-east-2')\n",
      "CPU times: user 540 ms, sys: 198 ms, total: 738 ms\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "import boto3 \n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "role='arn:aws:iam::395166463292:role/service-role/AmazonSageMaker-ExecutionRole-20200714T182988'\n",
    "from PIL import Image\n",
    "\n",
    "profile = 'crayon-site'\n",
    "region_name='us-east-2'\n",
    "bucket = 'st-crayon-dev'\n",
    "prefix = 'sagemaker/labelbox/'\n",
    "\n",
    "from botocore.exceptions import ProfileNotFound\n",
    "\n",
    "try:\n",
    "    boto3.setup_default_session(profile_name=profile)\n",
    "except ProfileNotFound:\n",
    "    print(\"crayon-site profile not found. Using default aws profile.\")\n",
    "\n",
    "session = boto3.session.Session(profile_name = profile, region_name = region_name)\n",
    "sess = sagemaker.Session(session,default_bucket=bucket)\n",
    "print(sess.boto_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Experiment\n",
    "Create an experiment to track all the model training iterations. Experiments are a great way to organize your data science work.  Think of it as a “folder” for organizing your “files”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of experiments : ['site-tech-drone-img-seg-full-res', 'labelbox-semantic-segmentation512', 'site-tech-drone-img-seg']\n",
      "Experiment used for notebook = labelbox-semantic-segmentation512\n"
     ]
    }
   ],
   "source": [
    "sm = session.client(service_name = 'sagemaker')\n",
    "\n",
    "experiment_name = f'labelbox-semantic-segmentation-all'\n",
    "\n",
    "experiments = []\n",
    "\n",
    "for exp in Experiment.list(sagemaker_boto_client=sm):\n",
    "    experiments.append(exp.experiment_name)\n",
    "\n",
    "print(f'List of experiments : {experiments}')\n",
    "\n",
    "if experiment_name not in experiments:\n",
    "    experiment = Experiment.create(experiment_name=experiment_name,\n",
    "                                   description=\"semantic segmentation of drone pictures\",\n",
    "                                   sagemaker_boto_client=sm)\n",
    "\n",
    "print(f'Experiment used for notebook = {experiment_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Experiment\n",
    "Create a Trial for each training run to track it's inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trial(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7f82f0e2d100>,trial_name='semantic-segmentation-labelbox-dataset-1024-1597188988',experiment_name='labelbox-semantic-segmentation512',tags=[{'Key': 'experiment_name', 'Value': 'aws-ss-drone-dataset'}],trial_arn='arn:aws:sagemaker:us-east-2:395166463292:experiment-trial/semantic-segmentation-labelbox-dataset-1024-1597188988',response_metadata={'RequestId': '1dbff408-fdf7-4885-b316-fce4bb147e61', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '1dbff408-fdf7-4885-b316-fce4bb147e61', 'content-type': 'application/x-amz-json-1.1', 'content-length': '127', 'date': 'Tue, 11 Aug 2020 23:36:28 GMT'}, 'RetryAttempts': 0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up parameters used for the hyperparameters and to name the trial\n",
    "num_training_samples = 2397 # 2397 and 11294\n",
    "base_size = 256\n",
    "crop_size = 224\n",
    "num_epochs = 70\n",
    "algorithm = 'fcn'\n",
    "tiles_type = 'tiles_1024'\n",
    "base_trial_name = f\"I{tiles_type.replace('_','-')}-B{base_size}-C{crop_size}-E{num_epochs}-{algorithm}\"\n",
    "# Add some randomness to each trial name\n",
    "rand_string = str(np.random.randint(1000)).zfill(4)\n",
    "trial_name = f'ssl-{base_trial_name}-{rand_string}'\n",
    "# Creating the trial\n",
    "ss_trial = Trial.create(trial_name = trial_name,\n",
    "                          experiment_name = experiment_name,\n",
    "                          sagemaker_boto_client = sm,\n",
    "                          tags = [{'Key': 'experiment_name', 'Value': 'aws-ss-drone-dataset'}])\n",
    "ss_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = f's3://{bucket}/{prefix}output'\n",
    "s3_output_checkpoints = f's3://{bucket}/{prefix}output/checkpoints'\n",
    "s3_output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training image\n",
    "Since we are using prebaked aws semantic segmentation algo, we need the Amazon SageMaker Semantic Segmentaion docker image. This is static and does not need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.amazon.amazon_estimator:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825641698319.dkr.ecr.us-east-2.amazonaws.com/semantic-segmentation:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (using Pipe Mode)\n",
    "\n",
    "In File-mode training data is downloaded to an encrypted EBS volume prior to commencing training. Once downloaded, the training algorithm simply trains by reading the downloaded training data files.\n",
    "\n",
    "On the other hand, in Pipe-mode the input data is transferred to the algorithm while it is training. This poses a few significant advantages over File-mode:\n",
    "\n",
    "\n",
    "*  In File-mode, training startup time is proportional to size of the input data. In Pipe-mode, the startup delay is constant, independent of the size of the input data. This translates to much faster training startup for training jobs with large GB/PB-scale training datasets.\n",
    "* You do not need to allocate (and pay for) a large disk volume to be able to download the dataset.\n",
    "* Throughput on IO-bound Pipe-mode algorithms can be multiple times faster than on equivalent File-mode algorithms.\n",
    "\n",
    "However, these advantages come at a cost - a more complicated programming model than simply reading from files on a disk. This notebook aims to clarify what you need to do in order to use Pipe-mode in your custom training algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare manifest file for data\n",
    "Manifest files should need to be created (but this only needs to be done once). There is a separate notebook `semantic_seg_create_manifest.ipynb` that performs this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare handshake \n",
    "We need to setup the data channels between our data channels and the algorithm. To do this, we need to create the `sagemaker.session.s3_input` objects from our data channels. In pipe mode, the data channels are the manifest files which contain the locations of the images and annotations in `s3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest_train='s3://st-crayon-dev/data/raw/imgs/tiles_1024/manifests/manifest_file_train_imgs.json'\n",
      "manifest_val='s3://st-crayon-dev/data/raw/imgs/tiles_1024/manifests/manifest_file_val_imgs.json'\n"
     ]
    }
   ],
   "source": [
    "manifest_train = f'data/raw/imgs/{tiles_type}/manifests/manifest_file_train_imgs.json'\n",
    "manifest_train = f's3://{bucket}/{manifest_train}'\n",
    "manifest_val = f'data/raw/imgs/{tiles_type}/manifests/manifest_file_val_imgs.json'\n",
    "manifest_val = f's3://{bucket}/{manifest_val}'\n",
    "\n",
    "print(f'{manifest_train=}\\n{manifest_val=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': <sagemaker.inputs.s3_input at 0x7f82f23555e0>,\n",
       " 'validation': <sagemaker.inputs.s3_input at 0x7f82f2355e20>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = 'FullyReplicated'\n",
    "# Create sagemaker s3_input objects\n",
    "train_data = sagemaker.session.s3_input(manifest_train, \n",
    "                                        distribution=distribution, \n",
    "                                        content_type='application/x-recordio',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', 'annotation-ref'],\n",
    "                                        input_mode='Pipe',\n",
    "                                        record_wrapping=\"RecordIO\")\n",
    "validation_data = sagemaker.session.s3_input(manifest_val, \n",
    "                                        distribution=distribution, \n",
    "                                        content_type='application/x-recordio',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', 'annotation-ref'],\n",
    "                                        input_mode='Pipe',\n",
    "                                        record_wrapping=\"RecordIO\")\n",
    "\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data}\n",
    "data_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "To begin training, we have to create ``sageMaker.estimator.Estimator`` object. This estimator will launch the training job. We name our training job as ``ssl-job-<train_params>``. For training, we need to select a gpu insatance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = f'ssl-job-{base_trial_name}-{rand_string}'\n",
    "\n",
    "ss_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role=role, \n",
    "                                         train_instance_count = 1, \n",
    "                                         train_instance_type = 'ml.p2.xlarge',\n",
    "                                         train_volume_size = 10,\n",
    "                                         train_max_run = 60 * 60 * 12,\n",
    "                                         train_max_wait= 60 * 60 * 18,\n",
    "                                         output_path = s3_output_location,\n",
    "                                         checkpoint_s3_uri = s3_output_checkpoints,\n",
    "                                         base_job_name = base_job_name,\n",
    "                                         train_use_spot_instances=True,\n",
    "                                         input_mode='Pipe',\n",
    "                                         sagemaker_session = sess,\n",
    "                                         enable_sagemaker_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic segmentation algorithm at its core has two compoenents.\n",
    "\n",
    "- An encoder (typically contains a CNN-based backbone)\n",
    "- A decoder network. \n",
    "\n",
    "The encoder is typically a regular convolutional neural network (CNN). The choice of the particular CNN to be used is called the backbone. The backbone can be selected to utilize pre-training on another task or be trained totally from scratch. The two backbones available for the AWS semantic segmentation algorithm are Resnet-101 and Resnet-50 ([ResNets](https://arxiv.org/abs/1512.03385) 50 or 101). If you select pre-trained models for these two backbones, they have been trained on Imagenet classification task [classification task of ImageNet images](http://www.image-net.org/).\n",
    "\n",
    "The decoder is a network that picks up the outputs of one or many layers from the backbone and reconstructs the segmentation mask from these inputs. Amazon SageMaker Semantic Segmentation algorithm comes with a choice of the [Fully-convolutional network (FCN)](https://arxiv.org/abs/1605.06211), the [Pyramid scene parsing (PSP) network](https://arxiv.org/abs/1612.01105) and [deeplab v3] (https://arxiv.org/abs/1706.05587).\n",
    "\n",
    "The algorithm also has ample options for hyperparameters that help configure the training job. One of the important steps during experimentation is figuring out the best networks and hyperparamenters. Consider the example definition of hyperparameters in the cell below and see the SageMaker Semantic Segmentation [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/semantic-segmentation.html) for more details on the hyperparameters.\n",
    "\n",
    "For instance, one of the hyperparameters here is the number of `epochs`. This defines how many times we pass through all the training examples in the dataset. This effects how long the model is allowed to train. Too little time and the model does not receive enough training and won't be powerful enough. If you let the training run too long, then it will just memorize the input and not generalize to unseen examples. There is always tradeoffs for each hyperparameter and the space needs to be explored to determine optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_model.set_hyperparameters(backbone='resnet-50', # This is the encoder. Other option is resnet-50\n",
    "                             algorithm=algorithm, # This is the decoder. Other option is 'fcn', 'psp' and 'deeplab'                             \n",
    "                             use_pretrained_model='True', # Use the pre-trained model.\n",
    "                             base_size=base_size,\n",
    "                             crop_size=crop_size, # Size of image random crop.                              \n",
    "                             num_classes=8, # Pascal has 21 classes. This is a mandatory parameter.\n",
    "                             epochs=num_epochs, # Number of epochs to run.\n",
    "                             learning_rate=0.001,                             \n",
    "                             optimizer='rmsprop', # Other options include 'adam', 'rmsprop', 'nag', 'adagrad'.\n",
    "                             lr_scheduler='poly', # Other options include 'cosine' and 'step'.                           \n",
    "                             mini_batch_size=16, # Setup some mini batch size.\n",
    "                             validation_mini_batch_size=16,\n",
    "                             early_stopping=True, # Turn on early stopping. If OFF, other early stopping parameters are ignored.\n",
    "                             early_stopping_patience=5, # Tolerate these many epochs if the mIoU doens't increase.\n",
    "                             early_stopping_tolerance=.001,\n",
    "                             early_stopping_min_epochs=10, # No matter what, run these many number of epochs.                             \n",
    "                             num_training_samples=num_training_samples) # This is a mandatory parameter, 1464 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'AugmentedManifestFile', 'S3Uri': 's3://st-crayon-dev/data/raw/imgs/tiles_1024/manifests/manifest_file_train_imgs.json', 'S3DataDistributionType': 'FullyReplicated', 'AttributeNames': ['source-ref', 'annotation-ref']}}, 'ContentType': 'application/x-recordio', 'RecordWrapperType': 'RecordIO', 'InputMode': 'Pipe'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'AugmentedManifestFile', 'S3Uri': 's3://st-crayon-dev/data/raw/imgs/tiles_1024/manifests/manifest_file_val_imgs.json', 'S3DataDistributionType': 'FullyReplicated', 'AttributeNames': ['source-ref', 'annotation-ref']}}, 'ContentType': 'application/x-recordio', 'RecordWrapperType': 'RecordIO', 'InputMode': 'Pipe'}\n"
     ]
    }
   ],
   "source": [
    "print(f'{train_data.config}\\n{validation_data.config}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: ss-labelbox-train-pipe-1597192033-2020-08-12-00-27-42-908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-12 00:27:43 Starting - Starting the training job...\n",
      "2020-08-12 00:27:45 Starting - Launching requested ML instances.........\n",
      "2020-08-12 00:29:20 Starting - Preparing the instances for training......\n",
      "2020-08-12 00:30:47 Downloading - Downloading input data\n",
      "2020-08-12 00:30:47 Training - Downloading the training image.........\n",
      "2020-08-12 00:32:11 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:14 INFO 139679679547200] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'syncbn': u'False', u'gamma2': u'0.9', u'gamma1': u'0.9', u'early_stopping_min_epochs': u'5', u'epochs': u'10', u'_workers': u'16', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0001', u'crop_size': u'240', u'use_pretrained_model': u'True', u'_aux_weight': u'0.5', u'_hybrid': u'False', u'_augmentation_type': u'default', u'lr_scheduler': u'poly', u'early_stopping_patience': u'4', u'momentum': u'0.9', u'optimizer': u'sgd', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'backbone': u'resnet-50', u'validation_mini_batch_size': u'16', u'_aux_loss': u'True', u'mini_batch_size': u'16', u'early_stopping': u'False', u'algorithm': u'fcn', u'_logging_frequency': u'20', u'num_training_samples': u'8', u'_kvstore': u'device', u'precision_dtype': u'float32'}\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:14 INFO 139679679547200] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'optimizer': u'rmsprop', u'algorithm': u'fcn', u'lr_scheduler': u'poly', u'use_pretrained_model': u'True', u'backbone': u'resnet-50', u'base_size': u'1024', u'early_stopping_min_epochs': u'2', u'epochs': u'20', u'early_stopping_tolerance': u'0.001', u'validation_mini_batch_size': u'16', u'num_training_samples': u'2361', u'num_classes': u'8', u'mini_batch_size': u'16', u'early_stopping_patience': u'5', u'early_stopping': u'True', u'crop_size': u'448'}\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:15 INFO 139679679547200] Final configuration: {u'syncbn': u'False', u'gamma2': u'0.9', u'gamma1': u'0.9', u'base_size': u'1024', u'early_stopping_min_epochs': u'2', u'epochs': u'20', u'_workers': u'16', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0001', u'crop_size': u'448', u'use_pretrained_model': u'True', u'_aux_weight': u'0.5', u'_hybrid': u'False', u'_augmentation_type': u'default', u'lr_scheduler': u'poly', u'num_classes': u'8', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'optimizer': u'rmsprop', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'0.001', u'backbone': u'resnet-50', u'validation_mini_batch_size': u'16', u'_aux_loss': u'True', u'mini_batch_size': u'16', u'early_stopping': u'True', u'algorithm': u'fcn', u'_logging_frequency': u'20', u'num_training_samples': u'2361', u'_kvstore': u'device', u'precision_dtype': u'float32'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:15 INFO 139679679547200] Using default worker.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:15 INFO 139679679547200] font search path ['/opt/amazon/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/amazon/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/amazon/lib/python2.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:15 INFO 139679679547200] generated new fontManager\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Loaded iterator creator application/json for content type ('application/json', '1.0')\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] The channel 'train' is in pipe input mode under /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] The channel 'train' is in pipe input mode under /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 WARNING 139679679547200] label maps not provided, using defaults.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] #label_map train :{'scale': 1}\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 0\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] The channel 'validation' is in pipe input mode under /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] The channel 'validation' is in pipe input mode under /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 WARNING 139679679547200] label maps not provided, using defaults.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] #label_map validation :{'scale': 1}\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 0\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] nvidia-smi took: 0.125571012497 secs to identify 8 gpus\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:16 INFO 139679679547200] Number of GPUs being used: 8\u001b[0m\n",
      "\u001b[34m[00:32:19] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:19] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:20] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:21] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:22] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:23] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[00:32:23] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x.1856.0/AL2012/generic-flavor/src/src/storage/storage.cc:108: Using GPUPooledRoundedStorageManager.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:32:34 INFO 139679679547200] LRScheduler setup: iters per epoch: 147, num_epochs 20\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1597192354.462769, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\"}, \"StartTime\": 1597192354.462674}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 00:33:39 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 20 speed: 13.065683281 samples/sec learning_rate: 0.000994\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:34:37 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 40 speed: 13.0313129634 samples/sec learning_rate: 0.000988\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:35:36 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 60 speed: 12.5782996947 samples/sec learning_rate: 0.000982\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:36:35 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 80 speed: 12.527658761 samples/sec learning_rate: 0.000975\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:37:33 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 100 speed: 12.6394085764 samples/sec learning_rate: 0.000969\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:38:32 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 120 speed: 13.0143507414 samples/sec learning_rate: 0.000963\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:39:31 INFO 139679679547200] #progress_notice. epoch: 0, iterations: 140 speed: 12.9601128443 samples/sec learning_rate: 0.000957\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:39:52 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 0, train loss: nan .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:39:52 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 0, train throughput: 12.5761005818 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:13 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 0, validation pixel_accuracy: 0.5462037751259606 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:13 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 0, validation mIOU: 0.15076327556499697 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:13 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 0, validation throughput: 35.3714839201 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:13 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:13 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:14 INFO 139679679547200] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1597192814.285871, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 0}, \"StartTime\": 1597192354.463267}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:14 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 1\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:40:14 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 1\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:41:11 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 20 speed: 12.7266025009 samples/sec learning_rate: 0.000949\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:42:09 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 40 speed: 12.9590241889 samples/sec learning_rate: 0.000943\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:43:09 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 60 speed: 13.0858588045 samples/sec learning_rate: 0.000936\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:44:09 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 80 speed: 12.9015909732 samples/sec learning_rate: 0.000930\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:45:07 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 100 speed: 12.9319044985 samples/sec learning_rate: 0.000924\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:46:05 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 120 speed: 12.9310498047 samples/sec learning_rate: 0.000918\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:04 INFO 139679679547200] #progress_notice. epoch: 1, iterations: 140 speed: 12.8040564609 samples/sec learning_rate: 0.000912\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:28 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 1, train loss: 1.7635179548398465 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:28 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 1, train throughput: 12.9713812369 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 1, validation pixel_accuracy: 0.5408131460630662 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 1, validation mIOU: 0.16300350309122105 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 1, validation throughput: 35.0213767872 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1597193269.664136, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 1}, \"StartTime\": 1597192814.286015}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 2\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:47:49 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 2\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:48:48 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 20 speed: 13.730146396 samples/sec learning_rate: 0.000903\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:49:46 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 40 speed: 13.0031292519 samples/sec learning_rate: 0.000897\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:50:45 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 60 speed: 12.9762262848 samples/sec learning_rate: 0.000891\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:51:42 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 80 speed: 12.3181254253 samples/sec learning_rate: 0.000884\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:52:39 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 100 speed: 13.0549572229 samples/sec learning_rate: 0.000878\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:53:38 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 120 speed: 12.8959978109 samples/sec learning_rate: 0.000872\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:54:36 INFO 139679679547200] #progress_notice. epoch: 2, iterations: 140 speed: 12.9548789622 samples/sec learning_rate: 0.000866\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:54:57 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 2, train loss: 1.6368664022801178 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:54:57 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 2, train throughput: 13.0949674693 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 2, validation pixel_accuracy: 0.5904381763829519 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 2, validation mIOU: 0.18963005502391878 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 2, validation throughput: 35.0114467429 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1597193719.956557, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 2}, \"StartTime\": 1597193269.66427}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 3\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:55:19 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 00:56:17 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 20 speed: 12.6570275983 samples/sec learning_rate: 0.000857\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:57:15 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 40 speed: 13.6298626389 samples/sec learning_rate: 0.000851\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:58:13 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 60 speed: 13.082700599 samples/sec learning_rate: 0.000845\u001b[0m\n",
      "\u001b[34m[08/12/2020 00:59:11 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 80 speed: 13.0006983804 samples/sec learning_rate: 0.000839\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:00:09 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 100 speed: 12.6132816288 samples/sec learning_rate: 0.000832\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:01:09 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 120 speed: 13.0427200527 samples/sec learning_rate: 0.000826\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:06 INFO 139679679547200] #progress_notice. epoch: 3, iterations: 140 speed: 13.0173800775 samples/sec learning_rate: 0.000820\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:30 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 3, train loss: 1.608637299821665 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:30 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 3, train throughput: 13.1394040071 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 3, validation pixel_accuracy: 0.5879775020156701 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 3, validation mIOU: 0.19753995453589981 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 3, validation throughput: 35.7494314507 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1597194171.918975, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 3}, \"StartTime\": 1597193719.956708}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 4\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:02:51 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 4\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:03:50 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 20 speed: 13.0498367916 samples/sec learning_rate: 0.000811\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:04:49 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 40 speed: 13.096720066 samples/sec learning_rate: 0.000805\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:05:47 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 60 speed: 13.5178386723 samples/sec learning_rate: 0.000799\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:06:46 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 80 speed: 13.0030259528 samples/sec learning_rate: 0.000792\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:07:44 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 100 speed: 13.1035095194 samples/sec learning_rate: 0.000786\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:08:42 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 120 speed: 13.6897691977 samples/sec learning_rate: 0.000780\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:09:40 INFO 139679679547200] #progress_notice. epoch: 4, iterations: 140 speed: 13.7130012937 samples/sec learning_rate: 0.000773\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:02 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 4, train loss: 1.5495307737578112 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:02 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 4, train throughput: 13.1608834787 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 4, validation pixel_accuracy: 0.5973863505165387 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 4, validation mIOU: 0.18899986604306535 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 4, validation throughput: 34.6558457422 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1597194624.566851, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 4}, \"StartTime\": 1597194171.919163}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 5\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:10:24 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 5\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:11:21 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 20 speed: 13.0468024781 samples/sec learning_rate: 0.000765\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:12:19 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 40 speed: 12.8858082242 samples/sec learning_rate: 0.000759\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:13:16 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 60 speed: 13.4274606723 samples/sec learning_rate: 0.000752\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:14:13 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 80 speed: 12.9990942513 samples/sec learning_rate: 0.000746\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:15:10 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 100 speed: 13.1228423255 samples/sec learning_rate: 0.000740\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:16:08 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 120 speed: 13.0705615821 samples/sec learning_rate: 0.000733\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:06 INFO 139679679547200] #progress_notice. epoch: 5, iterations: 140 speed: 13.036555618 samples/sec learning_rate: 0.000727\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:29 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 5, train loss: 1.5349039012370347 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:29 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 5, train throughput: 13.1025605876 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 5, validation pixel_accuracy: 0.6008325430915723 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 5, validation mIOU: 0.1848084973546988 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 5, validation throughput: 35.454130805 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1597195071.062863, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 5}, \"StartTime\": 1597194624.567068}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 6\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:17:51 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 01:18:47 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 20 speed: 12.9176014008 samples/sec learning_rate: 0.000718\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:19:46 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 40 speed: 13.0467086297 samples/sec learning_rate: 0.000712\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:20:45 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 60 speed: 13.006458375 samples/sec learning_rate: 0.000705\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:21:43 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 80 speed: 13.4489854772 samples/sec learning_rate: 0.000699\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:22:40 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 100 speed: 12.7613499687 samples/sec learning_rate: 0.000693\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:23:39 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 120 speed: 13.0400615114 samples/sec learning_rate: 0.000686\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:24:38 INFO 139679679547200] #progress_notice. epoch: 6, iterations: 140 speed: 13.0013129398 samples/sec learning_rate: 0.000680\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:00 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 6, train loss: 1.4822501811198099 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:00 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 6, train throughput: 13.113137709 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:21 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 6, validation pixel_accuracy: 0.6126160269198411 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:21 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 6, validation mIOU: 0.20127029569401633 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:21 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 6, validation throughput: 34.9573313984 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:21 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:22 INFO 139679679547200] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1597195522.239681, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 6}, \"StartTime\": 1597195071.063003}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:22 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 7\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:25:22 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 7\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:26:19 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 20 speed: 12.9891936828 samples/sec learning_rate: 0.000671\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:27:17 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 40 speed: 12.7016598176 samples/sec learning_rate: 0.000665\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:28:15 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 60 speed: 13.1821451294 samples/sec learning_rate: 0.000658\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:29:13 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 80 speed: 13.1079962084 samples/sec learning_rate: 0.000652\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:30:11 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 100 speed: 13.0584196612 samples/sec learning_rate: 0.000646\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:31:09 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 120 speed: 13.0960964542 samples/sec learning_rate: 0.000639\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:07 INFO 139679679547200] #progress_notice. epoch: 7, iterations: 140 speed: 13.0998620304 samples/sec learning_rate: 0.000633\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:31 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 7, train loss: 1.469348741440233 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:31 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 7, train throughput: 13.1171038323 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 7, validation pixel_accuracy: 0.6144290606160716 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 7, validation mIOU: 0.19647052835924145 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 7, validation throughput: 35.5822723743 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1597195972.944284, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 7}, \"StartTime\": 1597195522.239826}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 8\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:32:52 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 8\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:33:51 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 20 speed: 12.8874686594 samples/sec learning_rate: 0.000624\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:34:49 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 40 speed: 13.0779635993 samples/sec learning_rate: 0.000617\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:35:47 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 60 speed: 13.7157282887 samples/sec learning_rate: 0.000611\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:36:46 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 80 speed: 13.1342174958 samples/sec learning_rate: 0.000604\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:37:43 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 100 speed: 13.0433487319 samples/sec learning_rate: 0.000598\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:38:42 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 120 speed: 13.4890643464 samples/sec learning_rate: 0.000591\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:39:42 INFO 139679679547200] #progress_notice. epoch: 8, iterations: 140 speed: 13.0698895497 samples/sec learning_rate: 0.000585\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:06 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 8, train loss: 1.45378740241486 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:06 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 8, train throughput: 13.0629065998 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 8, validation pixel_accuracy: 0.5726257657430224 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 8, validation mIOU: 0.18744643756337845 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 8, validation throughput: 35.4857295221 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1597196427.162826, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 8}, \"StartTime\": 1597195972.944429}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 9\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:40:27 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 01:41:25 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 20 speed: 13.0270025158 samples/sec learning_rate: 0.000576\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:42:23 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 40 speed: 12.6773152124 samples/sec learning_rate: 0.000569\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:43:23 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 60 speed: 13.7377858351 samples/sec learning_rate: 0.000563\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:44:22 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 80 speed: 13.0201657863 samples/sec learning_rate: 0.000556\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:45:22 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 100 speed: 12.6952586918 samples/sec learning_rate: 0.000550\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:46:20 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 120 speed: 13.6584963961 samples/sec learning_rate: 0.000543\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:47:19 INFO 139679679547200] #progress_notice. epoch: 9, iterations: 140 speed: 12.8860383335 samples/sec learning_rate: 0.000537\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:47:41 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 9, train loss: 1.3988891507468826 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:47:41 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 9, train throughput: 13.0679673797 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 9, validation pixel_accuracy: 0.6217239311212226 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 9, validation mIOU: 0.21585346565914917 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 9, validation throughput: 35.3795363719 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1597196882.909965, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 9}, \"StartTime\": 1597196427.162968}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 10\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:02 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 10\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:48:59 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 20 speed: 12.7767561531 samples/sec learning_rate: 0.000528\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:49:58 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 40 speed: 13.0440586038 samples/sec learning_rate: 0.000521\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:50:55 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 60 speed: 13.3186835258 samples/sec learning_rate: 0.000514\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:51:54 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 80 speed: 13.1284080201 samples/sec learning_rate: 0.000508\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:52:52 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 100 speed: 13.6195587562 samples/sec learning_rate: 0.000501\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:53:51 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 120 speed: 13.1982369013 samples/sec learning_rate: 0.000495\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:54:50 INFO 139679679547200] #progress_notice. epoch: 10, iterations: 140 speed: 13.0931299998 samples/sec learning_rate: 0.000488\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:15 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 10, train loss: 1.3626507879183722 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:15 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 10, train throughput: 13.0461629441 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 10, validation pixel_accuracy: 0.6241031528447367 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 10, validation mIOU: 0.23433816180522538 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 10, validation throughput: 35.352071583 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1597197336.489699, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 10}, \"StartTime\": 1597196882.910124}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 11\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:55:36 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 11\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:56:35 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 20 speed: 13.1743635228 samples/sec learning_rate: 0.000479\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:57:33 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 40 speed: 13.046219118 samples/sec learning_rate: 0.000472\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:58:32 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 60 speed: 13.0973207319 samples/sec learning_rate: 0.000465\u001b[0m\n",
      "\u001b[34m[08/12/2020 01:59:31 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 80 speed: 13.164065162 samples/sec learning_rate: 0.000459\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:00:31 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 100 speed: 12.9238205779 samples/sec learning_rate: 0.000452\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:01:30 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 120 speed: 12.9510612967 samples/sec learning_rate: 0.000445\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:02:30 INFO 139679679547200] #progress_notice. epoch: 11, iterations: 140 speed: 12.9023425521 samples/sec learning_rate: 0.000439\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:02:51 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 11, train loss: 1.368341479963246 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:02:51 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 11, train throughput: 13.0419376857 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 11, validation pixel_accuracy: 0.6010223046858019 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 11, validation mIOU: 0.20685755916577778 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 11, validation throughput: 35.359139606 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1597197792.755583, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 11}, \"StartTime\": 1597197336.489838}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 12\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:03:12 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 02:04:09 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 20 speed: 12.6359934392 samples/sec learning_rate: 0.000430\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:05:08 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 40 speed: 12.9912304322 samples/sec learning_rate: 0.000423\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:06:06 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 60 speed: 12.7198555549 samples/sec learning_rate: 0.000416\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:07:04 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 80 speed: 13.1951254089 samples/sec learning_rate: 0.000409\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:08:02 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 100 speed: 13.0680087355 samples/sec learning_rate: 0.000403\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:09:01 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 120 speed: 12.8971106024 samples/sec learning_rate: 0.000396\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:09:59 INFO 139679679547200] #progress_notice. epoch: 12, iterations: 140 speed: 13.1695470019 samples/sec learning_rate: 0.000389\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:23 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 12, train loss: 1.2791971768963628 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:23 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 12, train throughput: 13.0607544329 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 12, validation pixel_accuracy: 0.6381792578027364 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 12, validation mIOU: 0.2388592174052535 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 12, validation throughput: 35.4671979349 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1597198244.509293, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 12}, \"StartTime\": 1597197792.755763}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 13\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:10:44 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 13\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:11:43 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 20 speed: 12.8644241947 samples/sec learning_rate: 0.000380\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:12:43 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 40 speed: 13.0916076907 samples/sec learning_rate: 0.000373\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:13:41 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 60 speed: 12.9784296434 samples/sec learning_rate: 0.000366\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:14:39 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 80 speed: 12.9258891587 samples/sec learning_rate: 0.000359\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:15:38 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 100 speed: 13.0135784863 samples/sec learning_rate: 0.000352\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:16:37 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 120 speed: 13.0518469133 samples/sec learning_rate: 0.000345\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:17:37 INFO 139679679547200] #progress_notice. epoch: 13, iterations: 140 speed: 12.5987612416 samples/sec learning_rate: 0.000338\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:17:58 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 13, train loss: 1.276247146283989 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:17:58 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 13, train throughput: 13.0690107198 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 13, validation pixel_accuracy: 0.6187429775962261 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 13, validation mIOU: 0.2148053283805296 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 13, validation throughput: 35.2666877779 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1597198700.220326, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 13}, \"StartTime\": 1597198244.509437}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 14\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:18:20 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 14\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:19:15 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 20 speed: 12.9723333391 samples/sec learning_rate: 0.000329\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:20:13 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 40 speed: 13.7968739303 samples/sec learning_rate: 0.000322\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:21:11 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 60 speed: 13.0027059882 samples/sec learning_rate: 0.000315\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:22:09 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 80 speed: 13.0231548666 samples/sec learning_rate: 0.000308\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:23:07 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 100 speed: 13.7327734267 samples/sec learning_rate: 0.000301\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:24:05 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 120 speed: 13.7292391099 samples/sec learning_rate: 0.000294\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:03 INFO 139679679547200] #progress_notice. epoch: 14, iterations: 140 speed: 12.8975989034 samples/sec learning_rate: 0.000287\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:26 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 14, train loss: 1.2469062469870158 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:26 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 14, train throughput: 13.0493446963 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:47 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 14, validation pixel_accuracy: 0.6636714810441605 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:47 INFO 139679679547200] #quality_metric. host: algo-1, epoch: 14, validation mIOU: 0.24662243846460932 .\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:47 INFO 139679679547200] #throughput_metric. host: algo-1, epoch: 14, validation throughput: 35.2822605292 samples/sec.\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:47 INFO 139679679547200] Serializing model to /opt/ml/model/model_best.params\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:48 INFO 139679679547200] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1597199148.20749, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 14}, \"StartTime\": 1597198700.220473}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:48 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/train, and epoch: 15\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:25:48 INFO 139679679547200] Initializing pipe reader with path: /opt/ml/input/data/validation, and epoch: 15\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[08/12/2020 02:26:46 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 20 speed: 12.9446810464 samples/sec learning_rate: 0.000277\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:27:44 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 40 speed: 13.039372343 samples/sec learning_rate: 0.000270\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:28:42 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 60 speed: 12.9186756468 samples/sec learning_rate: 0.000263\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:29:40 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 80 speed: 12.9224742403 samples/sec learning_rate: 0.000256\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:30:39 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 100 speed: 12.9050693109 samples/sec learning_rate: 0.000249\u001b[0m\n",
      "\u001b[34m[08/12/2020 02:31:37 INFO 139679679547200] #progress_notice. epoch: 15, iterations: 120 speed: 13.7233741381 samples/sec learning_rate: 0.000242\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1597199517.238148, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Semantic Segmentation\", \"epoch\": 15}, \"StartTime\": 1597199148.207634}\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/amazon/bin/sagemaker-train\", line 11, in <module>\n",
      "    load_entry_point('AIAlgorithmsSDK==1.0', 'console_scripts', 'sagemaker-train')()\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/train.py\", line 74, in main\n",
      "    worker(cfg)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/train.py\", line 402, in _run_worker\n",
      "    _execute_train(algo, cfg, training_data_iter, validation_data_iter, checkpoint_manager, current_host)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/ai_algorithms_sdk/train.py\", line 250, in _execute_train\n",
      "    result = algo.update(training_data_iter, validation_data_iter, epoch=epoch)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/algorithm/algo.py\", line 85, in update\n",
      "    train_loss, speed = self.controller.train(train_iter=train_iter._iterator, epoch=epoch)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/algorithm/trainer.py\", line 158, in train\n",
      "    output = self.trainer(data.astype(self.dtype, copy=False))\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/gluoncv/utils/parallel.py\", line 182, in __call__\n",
      "    return parallel_apply(self.module, inputs, kwargs, self.sync)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/gluoncv/utils/parallel.py\", line 317, in parallel_apply\n",
      "    for (input, kwargs) in zip(inputs, kwargs_tup)]\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 540, in __call__\n",
      "    out = self.forward(*args)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 917, in forward\n",
      "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/gluoncv/model_zoo/fcn.py\", line 57, in hybrid_forward\n",
      "    c3, c4 = self.base_forward(x)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/gluoncv/model_zoo/segbase.py\", line 83, in base_forward\n",
      "    c3 = self.layer3(x)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 540, in __call__\n",
      "    out = self.forward(*args)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 917, in forward\n",
      "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/nn/basic_layers.py\", line 117, in hybrid_forward\n",
      "    x = block(x)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 540, in __call__\n",
      "    out = self.forward(*args)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 917, in forward\n",
      "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/gluoncv/model_zoo/resnetv1b.py\", line 93, in hybrid_forward\n",
      "    out = self.conv2(out)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 540, in __call__\n",
      "    out = self.forward(*args)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/block.py\", line 917, in forward\n",
      "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/gluon/nn/conv_layers.py\", line 133, in hybrid_forward\n",
      "    act = getattr(F, self._op_name)(x, weight, name='fwd', **self._kwargs)\n",
      "  File \"<string>\", line 167, in Convolution\n",
      "  File \"/opt/amazon/lib/python2.7/site-packages/mxnet/_ctypes/ndarray.py\", line 92, in _imperative_invoke\n",
      "    ctypes.byref(out_stypes)))\u001b[0m\n",
      "\u001b[34mKeyboardInterrupt\u001b[0m\n",
      "\n",
      "2020-08-12 02:32:15 Stopping - Stopping the training job\n",
      "2020-08-12 02:32:15 Uploading - Uploading generated training model\n",
      "2020-08-12 02:32:37 MaxRuntimeExceeded - Training job runtime exceeded MaxRuntimeInSeconds provided\n",
      "Training seconds: 7296\n",
      "Billable seconds: 2189\n",
      "Managed Spot Training savings: 70.0%\n"
     ]
    }
   ],
   "source": [
    "ss_model.fit(inputs=data_channels,\n",
    "             logs=True,\n",
    "             experiment_config={\n",
    "                \"TrialName\": ss_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\": \"Training\",\n",
    "                },\n",
    "             wait=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
